{"version":3,"sources":["../src/openai-provider.ts","../src/openai-chat-language-model.ts","../src/convert-to-openai-chat-messages.ts","../src/map-openai-chat-logprobs.ts","../src/map-openai-finish-reason.ts","../src/openai-error.ts","../src/get-response-metadata.ts","../src/openai-prepare-tools.ts","../src/openai-completion-language-model.ts","../src/convert-to-openai-completion-prompt.ts","../src/map-openai-completion-logprobs.ts","../src/openai-embedding-model.ts","../src/openai-image-model.ts"],"sourcesContent":["import {\n  EmbeddingModelV1,\n  ImageModelV1,\n  LanguageModelV1,\n  ProviderV1,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIChatLanguageModel } from './openai-chat-language-model';\nimport { OpenAIChatModelId, OpenAIChatSettings } from './openai-chat-settings';\nimport { OpenAICompletionLanguageModel } from './openai-completion-language-model';\nimport {\n  OpenAICompletionModelId,\n  OpenAICompletionSettings,\n} from './openai-completion-settings';\nimport { OpenAIEmbeddingModel } from './openai-embedding-model';\nimport {\n  OpenAIEmbeddingModelId,\n  OpenAIEmbeddingSettings,\n} from './openai-embedding-settings';\nimport { OpenAIImageModel, OpenAIImageModelId } from './openai-image-model';\n\nexport interface OpenAIProvider extends ProviderV1 {\n  (\n    modelId: 'gpt-3.5-turbo-instruct',\n    settings?: OpenAICompletionSettings,\n  ): OpenAICompletionLanguageModel;\n  (modelId: OpenAIChatModelId, settings?: OpenAIChatSettings): LanguageModelV1;\n\n  /**\nCreates an OpenAI model for text generation.\n   */\n  languageModel(\n    modelId: 'gpt-3.5-turbo-instruct',\n    settings?: OpenAICompletionSettings,\n  ): OpenAICompletionLanguageModel;\n  languageModel(\n    modelId: OpenAIChatModelId,\n    settings?: OpenAIChatSettings,\n  ): LanguageModelV1;\n\n  /**\nCreates an OpenAI chat model for text generation.\n   */\n  chat(\n    modelId: OpenAIChatModelId,\n    settings?: OpenAIChatSettings,\n  ): LanguageModelV1;\n\n  /**\nCreates an OpenAI completion model for text generation.\n   */\n  completion(\n    modelId: OpenAICompletionModelId,\n    settings?: OpenAICompletionSettings,\n  ): LanguageModelV1;\n\n  /**\nCreates a model for text embeddings.\n   */\n  embedding(\n    modelId: OpenAIEmbeddingModelId,\n    settings?: OpenAIEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n\n  /**\nCreates a model for text embeddings.\n\n@deprecated Use `textEmbeddingModel` instead.\n   */\n  textEmbedding(\n    modelId: OpenAIEmbeddingModelId,\n    settings?: OpenAIEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbeddingModel(\n    modelId: OpenAIEmbeddingModelId,\n    settings?: OpenAIEmbeddingSettings,\n  ): EmbeddingModelV1<string>;\n\n  /**\nCreates a model for image generation.\n   */\n  image(modelId: OpenAIImageModelId): ImageModelV1;\n}\n\nexport interface OpenAIProviderSettings {\n  /**\nBase URL for the OpenAI API calls.\n     */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests.\n     */\n  apiKey?: string;\n\n  /**\nOpenAI Organization.\n     */\n  organization?: string;\n\n  /**\nOpenAI project.\n     */\n  project?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nOpenAI compatibility mode. Should be set to `strict` when using the OpenAI API,\nand `compatible` when using 3rd party providers. In `compatible` mode, newer\ninformation such as streamOptions are not being sent. Defaults to 'compatible'.\n   */\n  compatibility?: 'strict' | 'compatible';\n\n  /**\nProvider name. Overrides the `openai` default name for 3rd party providers.\n   */\n  name?: string;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate an OpenAI provider instance.\n */\nexport function createOpenAI(\n  options: OpenAIProviderSettings = {},\n): OpenAIProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ?? 'https://api.openai.com/v1';\n\n  // we default to compatible, because strict breaks providers like Groq:\n  const compatibility = options.compatibility ?? 'compatible';\n\n  const providerName = options.name ?? 'openai';\n\n  const getHeaders = () => ({\n    Authorization: `Bearer ${loadApiKey({\n      apiKey: options.apiKey,\n      environmentVariableName: 'OPENAI_API_KEY',\n      description: 'OpenAI',\n    })}`,\n    'OpenAI-Organization': options.organization,\n    'OpenAI-Project': options.project,\n    ...options.headers,\n  });\n\n  const createChatModel = (\n    modelId: OpenAIChatModelId,\n    settings: OpenAIChatSettings = {},\n  ) =>\n    new OpenAIChatLanguageModel(modelId, settings, {\n      provider: `${providerName}.chat`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      compatibility,\n      fetch: options.fetch,\n    });\n\n  const createCompletionModel = (\n    modelId: OpenAICompletionModelId,\n    settings: OpenAICompletionSettings = {},\n  ) =>\n    new OpenAICompletionLanguageModel(modelId, settings, {\n      provider: `${providerName}.completion`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      compatibility,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (\n    modelId: OpenAIEmbeddingModelId,\n    settings: OpenAIEmbeddingSettings = {},\n  ) =>\n    new OpenAIEmbeddingModel(modelId, settings, {\n      provider: `${providerName}.embedding`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (modelId: OpenAIImageModelId) =>\n    new OpenAIImageModel(modelId, {\n      provider: `${providerName}.image`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createLanguageModel = (\n    modelId: OpenAIChatModelId | OpenAICompletionModelId,\n    settings?: OpenAIChatSettings | OpenAICompletionSettings,\n  ) => {\n    if (new.target) {\n      throw new Error(\n        'The OpenAI model function cannot be called with the new keyword.',\n      );\n    }\n\n    if (modelId === 'gpt-3.5-turbo-instruct') {\n      return createCompletionModel(\n        modelId,\n        settings as OpenAICompletionSettings,\n      );\n    }\n\n    return createChatModel(modelId, settings as OpenAIChatSettings);\n  };\n\n  const provider = function (\n    modelId: OpenAIChatModelId | OpenAICompletionModelId,\n    settings?: OpenAIChatSettings | OpenAICompletionSettings,\n  ) {\n    return createLanguageModel(modelId, settings);\n  };\n\n  provider.languageModel = createLanguageModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  provider.image = createImageModel;\n\n  return provider as OpenAIProvider;\n}\n\n/**\nDefault OpenAI provider instance. It uses 'strict' compatibility mode.\n */\nexport const openai = createOpenAI({\n  compatibility: 'strict', // strict for OpenAI API\n});\n","import {\n\tInvalidResponseDataError,\n\tLanguageModelV1,\n\tLanguageModelV1CallWarning,\n\tLanguageModelV1FinishReason,\n\tLanguageModelV1LogProbs,\n\tLanguageModelV1ProviderMetadata,\n\tLanguageModelV1StreamPart,\n\tUnsupportedFunctionalityError,\n} from \"@ai-sdk/provider\";\nimport {\n\tFetchFunction,\n\tParseResult,\n\tcombineHeaders,\n\tcreateEventSourceResponseHandler,\n\tcreateJsonResponseHandler,\n\tgenerateId,\n\tisParsableJson,\n\tpostJsonToApi,\n} from \"@ai-sdk/provider-utils\";\nimport { z } from \"zod\";\nimport { convertToOpenAIChatMessages } from \"./convert-to-openai-chat-messages\";\nimport { mapOpenAIChatLogProbsOutput } from \"./map-openai-chat-logprobs\";\nimport { mapOpenAIFinishReason } from \"./map-openai-finish-reason\";\nimport { OpenAIChatModelId, OpenAIChatSettings } from \"./openai-chat-settings\";\nimport {\n\topenaiErrorDataSchema,\n\topenaiFailedResponseHandler,\n} from \"./openai-error\";\nimport { getResponseMetadata } from \"./get-response-metadata\";\nimport { prepareTools } from \"./openai-prepare-tools\";\n\ntype OpenAIChatConfig = {\n\tprovider: string;\n\tcompatibility: \"strict\" | \"compatible\";\n\theaders: () => Record<string, string | undefined>;\n\turl: (options: { modelId: string; path: string }) => string;\n\tfetch?: FetchFunction;\n};\n\nexport class OpenAIChatLanguageModel implements LanguageModelV1 {\n\treadonly specificationVersion = \"v1\";\n\n\treadonly modelId: OpenAIChatModelId;\n\treadonly settings: OpenAIChatSettings;\n\n\tprivate readonly config: OpenAIChatConfig;\n\n\tconstructor(\n\t\tmodelId: OpenAIChatModelId,\n\t\tsettings: OpenAIChatSettings,\n\t\tconfig: OpenAIChatConfig,\n\t) {\n\t\tthis.modelId = modelId;\n\t\tthis.settings = settings;\n\t\tthis.config = config;\n\t}\n\n\tget supportsStructuredOutputs(): boolean {\n\t\treturn this.settings.structuredOutputs ?? false;\n\t}\n\n\tget defaultObjectGenerationMode() {\n\t\t// audio models don't support structured outputs:\n\t\tif (isAudioModel(this.modelId)) {\n\t\t\treturn \"tool\";\n\t\t}\n\n\t\treturn this.supportsStructuredOutputs ? \"json\" : \"tool\";\n\t}\n\n\tget provider(): string {\n\t\treturn this.config.provider;\n\t}\n\n\tget supportsImageUrls(): boolean {\n\t\t// image urls can be sent if downloadImages is disabled (default):\n\t\treturn !this.settings.downloadImages;\n\t}\n\n\tprivate getArgs({\n\t\tmode,\n\t\tprompt,\n\t\tmaxTokens,\n\t\ttemperature,\n\t\ttopP,\n\t\ttopK,\n\t\tfrequencyPenalty,\n\t\tpresencePenalty,\n\t\tstopSequences,\n\t\tresponseFormat,\n\t\tseed,\n\t\tproviderMetadata,\n\t}: Parameters<LanguageModelV1[\"doGenerate\"]>[0]) {\n\t\tconst type = mode.type;\n\n\t\tconst warnings: LanguageModelV1CallWarning[] = [];\n\n\t\tif (topK != null) {\n\t\t\twarnings.push({\n\t\t\t\ttype: \"unsupported-setting\",\n\t\t\t\tsetting: \"topK\",\n\t\t\t});\n\t\t}\n\n\t\tif (\n\t\t\tresponseFormat?.type === \"json\" &&\n\t\t\tresponseFormat.schema != null &&\n\t\t\t!this.supportsStructuredOutputs\n\t\t) {\n\t\t\twarnings.push({\n\t\t\t\ttype: \"unsupported-setting\",\n\t\t\t\tsetting: \"responseFormat\",\n\t\t\t\tdetails:\n\t\t\t\t\t\"JSON response format schema is only supported with structuredOutputs\",\n\t\t\t});\n\t\t}\n\n\t\tconst useLegacyFunctionCalling = this.settings.useLegacyFunctionCalling;\n\n\t\tif (useLegacyFunctionCalling && this.settings.parallelToolCalls === true) {\n\t\t\tthrow new UnsupportedFunctionalityError({\n\t\t\t\tfunctionality: \"useLegacyFunctionCalling with parallelToolCalls\",\n\t\t\t});\n\t\t}\n\n\t\tif (useLegacyFunctionCalling && this.supportsStructuredOutputs) {\n\t\t\tthrow new UnsupportedFunctionalityError({\n\t\t\t\tfunctionality: \"structuredOutputs with useLegacyFunctionCalling\",\n\t\t\t});\n\t\t}\n\n\t\tconst baseArgs = {\n\t\t\t// model id:\n\t\t\tmodel: this.modelId,\n\n\t\t\t// model specific settings:\n\t\t\tlogit_bias: this.settings.logitBias,\n\t\t\tlogprobs:\n\t\t\t\tthis.settings.logprobs === true ||\n\t\t\t\ttypeof this.settings.logprobs === \"number\"\n\t\t\t\t\t? true\n\t\t\t\t\t: undefined,\n\t\t\ttop_logprobs:\n\t\t\t\ttypeof this.settings.logprobs === \"number\"\n\t\t\t\t\t? this.settings.logprobs\n\t\t\t\t\t: typeof this.settings.logprobs === \"boolean\"\n\t\t\t\t\t\t? this.settings.logprobs\n\t\t\t\t\t\t\t? 0\n\t\t\t\t\t\t\t: undefined\n\t\t\t\t\t\t: undefined,\n\t\t\tuser: this.settings.user,\n\t\t\tparallel_tool_calls: this.settings.parallelToolCalls,\n\n\t\t\t// standardized settings:\n\t\t\tmax_tokens: maxTokens,\n\t\t\ttemperature,\n\t\t\ttop_p: topP,\n\t\t\tfrequency_penalty: frequencyPenalty,\n\t\t\tpresence_penalty: presencePenalty,\n\t\t\tresponse_format:\n\t\t\t\tresponseFormat?.type === \"json\"\n\t\t\t\t\t? this.supportsStructuredOutputs && responseFormat.schema != null\n\t\t\t\t\t\t? {\n\t\t\t\t\t\t\t\ttype: \"json_schema\",\n\t\t\t\t\t\t\t\tjson_schema: {\n\t\t\t\t\t\t\t\t\tschema: responseFormat.schema,\n\t\t\t\t\t\t\t\t\tstrict: true,\n\t\t\t\t\t\t\t\t\tname: responseFormat.name ?? \"response\",\n\t\t\t\t\t\t\t\t\tdescription: responseFormat.description,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t: { type: \"json_object\" }\n\t\t\t\t\t: undefined,\n\t\t\tstop: stopSequences,\n\t\t\tseed,\n\n\t\t\t// openai specific settings:\n\t\t\tmax_completion_tokens: providerMetadata?.openai?.maxCompletionTokens,\n\t\t\tstore: providerMetadata?.openai?.store,\n\t\t\tmetadata: providerMetadata?.openai?.metadata,\n\t\t\tprediction: providerMetadata?.openai?.prediction,\n\t\t\treasoning_effort:\n\t\t\t\tproviderMetadata?.openai?.reasoningEffort ??\n\t\t\t\tthis.settings.reasoningEffort,\n\n\t\t\t// messages:\n\t\t\tmessages: convertToOpenAIChatMessages({\n\t\t\t\tprompt,\n\t\t\t\tuseLegacyFunctionCalling,\n\t\t\t}),\n\t\t};\n\n\t\t// reasoning models have fixed params, remove them if they are set:\n\t\tif (isReasoningModel(this.modelId)) {\n\t\t\tbaseArgs.temperature = undefined;\n\t\t\tbaseArgs.top_p = undefined;\n\t\t\tbaseArgs.frequency_penalty = undefined;\n\t\t\tbaseArgs.presence_penalty = undefined;\n\t\t}\n\n\t\tswitch (type) {\n\t\t\tcase \"regular\": {\n\t\t\t\tconst { tools, tool_choice, functions, function_call, toolWarnings } =\n\t\t\t\t\tprepareTools({\n\t\t\t\t\t\tmode,\n\t\t\t\t\t\tuseLegacyFunctionCalling,\n\t\t\t\t\t\tstructuredOutputs: this.supportsStructuredOutputs,\n\t\t\t\t\t});\n\n\t\t\t\treturn {\n\t\t\t\t\targs: {\n\t\t\t\t\t\t...baseArgs,\n\t\t\t\t\t\ttools,\n\t\t\t\t\t\ttool_choice,\n\t\t\t\t\t\tfunctions,\n\t\t\t\t\t\tfunction_call,\n\t\t\t\t\t},\n\t\t\t\t\twarnings: [...warnings, ...toolWarnings],\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tcase \"object-json\": {\n\t\t\t\treturn {\n\t\t\t\t\targs: {\n\t\t\t\t\t\t...baseArgs,\n\t\t\t\t\t\tresponse_format:\n\t\t\t\t\t\t\tthis.supportsStructuredOutputs && mode.schema != null\n\t\t\t\t\t\t\t\t? {\n\t\t\t\t\t\t\t\t\t\ttype: \"json_schema\",\n\t\t\t\t\t\t\t\t\t\tjson_schema: {\n\t\t\t\t\t\t\t\t\t\t\tschema: mode.schema,\n\t\t\t\t\t\t\t\t\t\t\tstrict: true,\n\t\t\t\t\t\t\t\t\t\t\tname: mode.name ?? \"response\",\n\t\t\t\t\t\t\t\t\t\t\tdescription: mode.description,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t: { type: \"json_object\" },\n\t\t\t\t\t},\n\t\t\t\t\twarnings,\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tcase \"object-tool\": {\n\t\t\t\treturn {\n\t\t\t\t\targs: useLegacyFunctionCalling\n\t\t\t\t\t\t? {\n\t\t\t\t\t\t\t\t...baseArgs,\n\t\t\t\t\t\t\t\tfunction_call: {\n\t\t\t\t\t\t\t\t\tname: mode.tool.name,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tfunctions: [\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tname: mode.tool.name,\n\t\t\t\t\t\t\t\t\t\tdescription: mode.tool.description,\n\t\t\t\t\t\t\t\t\t\tparameters: mode.tool.parameters,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t: {\n\t\t\t\t\t\t\t\t...baseArgs,\n\t\t\t\t\t\t\t\ttool_choice: {\n\t\t\t\t\t\t\t\t\ttype: \"function\",\n\t\t\t\t\t\t\t\t\tfunction: { name: mode.tool.name },\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\ttools: [\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\ttype: \"function\",\n\t\t\t\t\t\t\t\t\t\tfunction: {\n\t\t\t\t\t\t\t\t\t\t\tname: mode.tool.name,\n\t\t\t\t\t\t\t\t\t\t\tdescription: mode.tool.description,\n\t\t\t\t\t\t\t\t\t\t\tparameters: mode.tool.parameters,\n\t\t\t\t\t\t\t\t\t\t\tstrict: this.supportsStructuredOutputs ? true : undefined,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t},\n\t\t\t\t\twarnings,\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tdefault: {\n\t\t\t\tconst _exhaustiveCheck: never = type;\n\t\t\t\tthrow new Error(`Unsupported type: ${_exhaustiveCheck}`);\n\t\t\t}\n\t\t}\n\t}\n\n\tasync doGenerate(\n\t\toptions: Parameters<LanguageModelV1[\"doGenerate\"]>[0],\n\t): Promise<Awaited<ReturnType<LanguageModelV1[\"doGenerate\"]>>> {\n\t\tconst { args: body, warnings } = this.getArgs(options);\n\n\t\tconst { responseHeaders, value: response } = await postJsonToApi({\n\t\t\turl: this.config.url({\n\t\t\t\tpath: \"/chat/completions\",\n\t\t\t\tmodelId: this.modelId,\n\t\t\t}),\n\t\t\theaders: combineHeaders(this.config.headers(), options.headers),\n\t\t\tbody,\n\t\t\tfailedResponseHandler: openaiFailedResponseHandler,\n\t\t\tsuccessfulResponseHandler: createJsonResponseHandler(\n\t\t\t\topenaiChatResponseSchema,\n\t\t\t),\n\t\t\tabortSignal: options.abortSignal,\n\t\t\tfetch: this.config.fetch,\n\t\t});\n\n\t\tconst { messages: rawPrompt, ...rawSettings } = body;\n\t\tconst choice = response.choices[0];\n\n\t\tlet providerMetadata: LanguageModelV1ProviderMetadata | undefined;\n\t\tif (\n\t\t\tresponse.usage?.completion_tokens_details?.reasoning_tokens != null ||\n\t\t\tresponse.usage?.prompt_tokens_details?.cached_tokens != null\n\t\t) {\n\t\t\tproviderMetadata = { openai: {} };\n\t\t\tif (response.usage?.completion_tokens_details?.reasoning_tokens != null) {\n\t\t\t\tproviderMetadata.openai.reasoningTokens =\n\t\t\t\t\tresponse.usage?.completion_tokens_details?.reasoning_tokens;\n\t\t\t}\n\t\t\tif (response.usage?.prompt_tokens_details?.cached_tokens != null) {\n\t\t\t\tproviderMetadata.openai.cachedPromptTokens =\n\t\t\t\t\tresponse.usage?.prompt_tokens_details?.cached_tokens;\n\t\t\t}\n\t\t}\n\n\t\treturn {\n\t\t\ttext: choice.message.content ?? undefined,\n\t\t\ttoolCalls:\n\t\t\t\tthis.settings.useLegacyFunctionCalling && choice.message.function_call\n\t\t\t\t\t? [\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\t\ttoolCallId: generateId(),\n\t\t\t\t\t\t\t\ttoolName: choice.message.function_call.name,\n\t\t\t\t\t\t\t\targs: choice.message.function_call.arguments,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t]\n\t\t\t\t\t: choice.message.tool_calls?.map((toolCall) => ({\n\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\ttoolCallId: toolCall.id ?? generateId(),\n\t\t\t\t\t\t\ttoolName: toolCall.function.name,\n\t\t\t\t\t\t\targs: toolCall.function.arguments!,\n\t\t\t\t\t\t})),\n\t\t\tfinishReason: mapOpenAIFinishReason(choice.finish_reason),\n\t\t\tusage: {\n\t\t\t\tpromptTokens: response.usage?.prompt_tokens ?? NaN,\n\t\t\t\tcompletionTokens: response.usage?.completion_tokens ?? NaN,\n\t\t\t},\n\t\t\trawCall: { rawPrompt, rawSettings },\n\t\t\trawResponse: { headers: responseHeaders },\n\t\t\trequest: { body: JSON.stringify(body) },\n\t\t\tresponse: getResponseMetadata(response),\n\t\t\twarnings,\n\t\t\tlogprobs: mapOpenAIChatLogProbsOutput(choice.logprobs),\n\t\t\tproviderMetadata,\n\t\t};\n\t}\n\n\tasync doStream(\n\t\toptions: Parameters<LanguageModelV1[\"doStream\"]>[0],\n\t): Promise<Awaited<ReturnType<LanguageModelV1[\"doStream\"]>>> {\n\t\tif (this.settings.simulateStreaming) {\n\t\t\tconst result = await this.doGenerate(options);\n\t\t\tconst simulatedStream = new ReadableStream<LanguageModelV1StreamPart>({\n\t\t\t\tstart(controller) {\n\t\t\t\t\tcontroller.enqueue({ type: \"response-metadata\", ...result.response });\n\t\t\t\t\tif (result.text) {\n\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\ttype: \"text-delta\",\n\t\t\t\t\t\t\ttextDelta: result.text,\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\tif (result.toolCalls) {\n\t\t\t\t\t\tfor (const toolCall of result.toolCalls) {\n\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\ttype: \"tool-call\",\n\t\t\t\t\t\t\t\t...toolCall,\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\ttype: \"finish\",\n\t\t\t\t\t\tfinishReason: result.finishReason,\n\t\t\t\t\t\tusage: result.usage,\n\t\t\t\t\t\tlogprobs: result.logprobs,\n\t\t\t\t\t\tproviderMetadata: result.providerMetadata,\n\t\t\t\t\t});\n\t\t\t\t\tcontroller.close();\n\t\t\t\t},\n\t\t\t});\n\t\t\treturn {\n\t\t\t\tstream: simulatedStream,\n\t\t\t\trawCall: result.rawCall,\n\t\t\t\trawResponse: result.rawResponse,\n\t\t\t\twarnings: result.warnings,\n\t\t\t};\n\t\t}\n\n\t\tconst { args, warnings } = this.getArgs(options);\n\n\t\tconst body = {\n\t\t\t...args,\n\t\t\tstream: true,\n\n\t\t\t// only include stream_options when in strict compatibility mode:\n\t\t\tstream_options:\n\t\t\t\tthis.config.compatibility === \"strict\"\n\t\t\t\t\t? { include_usage: true }\n\t\t\t\t\t: undefined,\n\t\t};\n\n\t\tconst { responseHeaders, value: response } = await postJsonToApi({\n\t\t\turl: this.config.url({\n\t\t\t\tpath: \"/chat/completions\",\n\t\t\t\tmodelId: this.modelId,\n\t\t\t}),\n\t\t\theaders: combineHeaders(this.config.headers(), options.headers),\n\t\t\tbody,\n\t\t\tfailedResponseHandler: openaiFailedResponseHandler,\n\t\t\tsuccessfulResponseHandler: createEventSourceResponseHandler(\n\t\t\t\topenaiChatChunkSchema,\n\t\t\t),\n\t\t\tabortSignal: options.abortSignal,\n\t\t\tfetch: this.config.fetch,\n\t\t});\n\n\t\tconst { messages: rawPrompt, ...rawSettings } = args;\n\n\t\tconst toolCalls: Array<{\n\t\t\tid: string;\n\t\t\ttype: \"function\";\n\t\t\tfunction: {\n\t\t\t\tname: string;\n\t\t\t\targuments: string;\n\t\t\t};\n\t\t\thasFinished: boolean;\n\t\t}> = [];\n\n\t\tlet finishReason: LanguageModelV1FinishReason = \"unknown\";\n\t\tlet usage: {\n\t\t\tpromptTokens: number | undefined;\n\t\t\tcompletionTokens: number | undefined;\n\t\t} = {\n\t\t\tpromptTokens: undefined,\n\t\t\tcompletionTokens: undefined,\n\t\t};\n\t\tlet logprobs: LanguageModelV1LogProbs;\n\t\tlet isFirstChunk = true;\n\n\t\tconst { useLegacyFunctionCalling } = this.settings;\n\n\t\tlet providerMetadata: LanguageModelV1ProviderMetadata | undefined;\n\t\treturn {\n\t\t\tstream: response.pipeThrough(\n\t\t\t\tnew TransformStream<\n\t\t\t\t\tParseResult<z.infer<typeof openaiChatChunkSchema>>,\n\t\t\t\t\tLanguageModelV1StreamPart\n\t\t\t\t>({\n\t\t\t\t\ttransform(chunk, controller) {\n\t\t\t\t\t\t// handle failed chunk parsing / validation:\n\t\t\t\t\t\tif (!chunk.success) {\n\t\t\t\t\t\t\tfinishReason = \"error\";\n\t\t\t\t\t\t\tcontroller.enqueue({ type: \"error\", error: chunk.error });\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst value = chunk.value;\n\n\t\t\t\t\t\t// handle error chunks:\n\t\t\t\t\t\tif (\"error\" in value) {\n\t\t\t\t\t\t\tfinishReason = \"error\";\n\t\t\t\t\t\t\tcontroller.enqueue({ type: \"error\", error: value.error });\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (isFirstChunk) {\n\t\t\t\t\t\t\tisFirstChunk = false;\n\n\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\ttype: \"response-metadata\",\n\t\t\t\t\t\t\t\t...getResponseMetadata(value),\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (value.usage != null) {\n\t\t\t\t\t\t\tusage = {\n\t\t\t\t\t\t\t\tpromptTokens: value.usage.prompt_tokens ?? undefined,\n\t\t\t\t\t\t\t\tcompletionTokens: value.usage.completion_tokens ?? undefined,\n\t\t\t\t\t\t\t};\n\n\t\t\t\t\t\t\tconst {\n\t\t\t\t\t\t\t\tcompletion_tokens_details: completionTokenDetails,\n\t\t\t\t\t\t\t\tprompt_tokens_details: promptTokenDetails,\n\t\t\t\t\t\t\t} = value.usage;\n\n\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\tcompletionTokenDetails?.reasoning_tokens != null ||\n\t\t\t\t\t\t\t\tpromptTokenDetails?.cached_tokens != null\n\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\tproviderMetadata = { openai: {} };\n\t\t\t\t\t\t\t\tif (completionTokenDetails?.reasoning_tokens != null) {\n\t\t\t\t\t\t\t\t\tproviderMetadata.openai.reasoningTokens =\n\t\t\t\t\t\t\t\t\t\tcompletionTokenDetails?.reasoning_tokens;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (promptTokenDetails?.cached_tokens != null) {\n\t\t\t\t\t\t\t\t\tproviderMetadata.openai.cachedPromptTokens =\n\t\t\t\t\t\t\t\t\t\tpromptTokenDetails?.cached_tokens;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst choice = value.choices[0];\n\n\t\t\t\t\t\tif (choice?.finish_reason != null) {\n\t\t\t\t\t\t\tfinishReason = mapOpenAIFinishReason(choice.finish_reason);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (choice?.delta == null) {\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst delta = choice.delta;\n\n\t\t\t\t\t\tif (delta.content != null) {\n\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\ttype: \"text-delta\",\n\t\t\t\t\t\t\t\ttextDelta: delta.content,\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst mappedLogprobs = mapOpenAIChatLogProbsOutput(\n\t\t\t\t\t\t\tchoice?.logprobs,\n\t\t\t\t\t\t);\n\t\t\t\t\t\tif (mappedLogprobs?.length) {\n\t\t\t\t\t\t\tif (logprobs === undefined) logprobs = [];\n\t\t\t\t\t\t\tlogprobs.push(...mappedLogprobs);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst mappedToolCalls: typeof delta.tool_calls =\n\t\t\t\t\t\t\tuseLegacyFunctionCalling && delta.function_call != null\n\t\t\t\t\t\t\t\t? [\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\ttype: \"function\",\n\t\t\t\t\t\t\t\t\t\t\tid: generateId(),\n\t\t\t\t\t\t\t\t\t\t\tfunction: delta.function_call,\n\t\t\t\t\t\t\t\t\t\t\tindex: 0,\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t: delta.tool_calls;\n\n\t\t\t\t\t\tif (mappedToolCalls != null) {\n\t\t\t\t\t\t\tfor (const toolCallDelta of mappedToolCalls) {\n\t\t\t\t\t\t\t\tconst index = toolCallDelta.index;\n\n\t\t\t\t\t\t\t\t// Tool call start. OpenAI returns all information except the arguments in the first chunk.\n\t\t\t\t\t\t\t\tif (toolCalls[index] == null) {\n\t\t\t\t\t\t\t\t\tif (toolCallDelta.type !== \"function\") {\n\t\t\t\t\t\t\t\t\t\tthrow new InvalidResponseDataError({\n\t\t\t\t\t\t\t\t\t\t\tdata: toolCallDelta,\n\t\t\t\t\t\t\t\t\t\t\tmessage: `Expected 'function' type.`,\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\tif (toolCallDelta.id == null) {\n\t\t\t\t\t\t\t\t\t\tthrow new InvalidResponseDataError({\n\t\t\t\t\t\t\t\t\t\t\tdata: toolCallDelta,\n\t\t\t\t\t\t\t\t\t\t\tmessage: `Expected 'id' to be a string.`,\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\tif (toolCallDelta.function?.name == null) {\n\t\t\t\t\t\t\t\t\t\tthrow new InvalidResponseDataError({\n\t\t\t\t\t\t\t\t\t\t\tdata: toolCallDelta,\n\t\t\t\t\t\t\t\t\t\t\tmessage: `Expected 'function.name' to be a string.`,\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\ttoolCalls[index] = {\n\t\t\t\t\t\t\t\t\t\tid: toolCallDelta.id,\n\t\t\t\t\t\t\t\t\t\ttype: \"function\",\n\t\t\t\t\t\t\t\t\t\tfunction: {\n\t\t\t\t\t\t\t\t\t\t\tname: toolCallDelta.function.name,\n\t\t\t\t\t\t\t\t\t\t\targuments: toolCallDelta.function.arguments ?? \"\",\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\thasFinished: false,\n\t\t\t\t\t\t\t\t\t};\n\n\t\t\t\t\t\t\t\t\tconst toolCall = toolCalls[index];\n\n\t\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\t\ttoolCall.function?.name != null &&\n\t\t\t\t\t\t\t\t\t\ttoolCall.function?.arguments != null\n\t\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\t\t// send delta if the argument text has already started:\n\t\t\t\t\t\t\t\t\t\tif (toolCall.function.arguments.length > 0) {\n\t\t\t\t\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\t\t\t\t\ttype: \"tool-call-delta\",\n\t\t\t\t\t\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\t\t\t\t\t\ttoolCallId: toolCall.id,\n\t\t\t\t\t\t\t\t\t\t\t\ttoolName: toolCall.function.name,\n\t\t\t\t\t\t\t\t\t\t\t\targsTextDelta: toolCall.function.arguments,\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\t\t// check if tool call is complete\n\t\t\t\t\t\t\t\t\t\t// (some providers send the full tool call in one chunk):\n\t\t\t\t\t\t\t\t\t\tif (isParsableJson(toolCall.function.arguments)) {\n\t\t\t\t\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\t\t\t\t\ttype: \"tool-call\",\n\t\t\t\t\t\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\t\t\t\t\t\ttoolCallId: toolCall.id ?? generateId(),\n\t\t\t\t\t\t\t\t\t\t\t\ttoolName: toolCall.function.name,\n\t\t\t\t\t\t\t\t\t\t\t\targs: toolCall.function.arguments,\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t\ttoolCall.hasFinished = true;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t// existing tool call, merge if not finished\n\t\t\t\t\t\t\t\tconst toolCall = toolCalls[index];\n\n\t\t\t\t\t\t\t\tif (toolCall.hasFinished) {\n\t\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tif (toolCallDelta.function?.arguments != null) {\n\t\t\t\t\t\t\t\t\ttoolCall.function!.arguments +=\n\t\t\t\t\t\t\t\t\t\ttoolCallDelta.function?.arguments ?? \"\";\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t// send delta\n\t\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\t\ttype: \"tool-call-delta\",\n\t\t\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\t\t\ttoolCallId: toolCall.id,\n\t\t\t\t\t\t\t\t\ttoolName: toolCall.function.name,\n\t\t\t\t\t\t\t\t\targsTextDelta: toolCallDelta.function.arguments ?? \"\",\n\t\t\t\t\t\t\t\t});\n\n\t\t\t\t\t\t\t\t// check if tool call is complete\n\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\ttoolCall.function?.name != null &&\n\t\t\t\t\t\t\t\t\ttoolCall.function?.arguments != null &&\n\t\t\t\t\t\t\t\t\tisParsableJson(toolCall.function.arguments)\n\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\t\t\t\ttype: \"tool-call\",\n\t\t\t\t\t\t\t\t\t\ttoolCallType: \"function\",\n\t\t\t\t\t\t\t\t\t\ttoolCallId: toolCall.id ?? generateId(),\n\t\t\t\t\t\t\t\t\t\ttoolName: toolCall.function.name,\n\t\t\t\t\t\t\t\t\t\targs: toolCall.function.arguments,\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\ttoolCall.hasFinished = true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t},\n\n\t\t\t\t\tflush(controller) {\n\t\t\t\t\t\tcontroller.enqueue({\n\t\t\t\t\t\t\ttype: \"finish\",\n\t\t\t\t\t\t\tfinishReason,\n\t\t\t\t\t\t\tlogprobs,\n\t\t\t\t\t\t\tusage: {\n\t\t\t\t\t\t\t\tpromptTokens: usage.promptTokens ?? NaN,\n\t\t\t\t\t\t\t\tcompletionTokens: usage.completionTokens ?? NaN,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t...(providerMetadata != null ? { providerMetadata } : {}),\n\t\t\t\t\t\t});\n\t\t\t\t\t},\n\t\t\t\t}),\n\t\t\t),\n\t\t\trawCall: { rawPrompt, rawSettings },\n\t\t\trawResponse: { headers: responseHeaders },\n\t\t\trequest: { body: JSON.stringify(body) },\n\t\t\twarnings,\n\t\t};\n\t}\n}\n\nconst openaiTokenUsageSchema = z\n\t.object({\n\t\tprompt_tokens: z.number().nullish(),\n\t\tcompletion_tokens: z.number().nullish(),\n\t\tprompt_tokens_details: z\n\t\t\t.object({\n\t\t\t\tcached_tokens: z.number().nullish(),\n\t\t\t})\n\t\t\t.nullish(),\n\t\tcompletion_tokens_details: z\n\t\t\t.object({\n\t\t\t\treasoning_tokens: z.number().nullish(),\n\t\t\t})\n\t\t\t.nullish(),\n\t})\n\t.nullish();\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatResponseSchema = z.object({\n\tid: z.string().nullish(),\n\tcreated: z.number().nullish(),\n\tmodel: z.string().nullish(),\n\tchoices: z.array(\n\t\tz.object({\n\t\t\tmessage: z.object({\n\t\t\t\trole: z.literal(\"assistant\").nullish(),\n\t\t\t\tcontent: z.string().nullish(),\n\t\t\t\tfunction_call: z\n\t\t\t\t\t.object({\n\t\t\t\t\t\targuments: z.string(),\n\t\t\t\t\t\tname: z.string(),\n\t\t\t\t\t})\n\t\t\t\t\t.nullish(),\n\t\t\t\ttool_calls: z\n\t\t\t\t\t.array(\n\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\tid: z.string().nullish(),\n\t\t\t\t\t\t\ttype: z.literal(\"function\"),\n\t\t\t\t\t\t\tfunction: z.object({\n\t\t\t\t\t\t\t\tname: z.string(),\n\t\t\t\t\t\t\t\targuments: z.string(),\n\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t}),\n\t\t\t\t\t)\n\t\t\t\t\t.nullish(),\n\t\t\t}),\n\t\t\tindex: z.number(),\n\t\t\tlogprobs: z\n\t\t\t\t.object({\n\t\t\t\t\tcontent: z\n\t\t\t\t\t\t.array(\n\t\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\t\ttoken: z.string(),\n\t\t\t\t\t\t\t\tlogprob: z.number(),\n\t\t\t\t\t\t\t\ttop_logprobs: z.array(\n\t\t\t\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\t\t\t\ttoken: z.string(),\n\t\t\t\t\t\t\t\t\t\tlogprob: z.number(),\n\t\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t)\n\t\t\t\t\t\t.nullable(),\n\t\t\t\t})\n\t\t\t\t.nullish(),\n\t\t\tfinish_reason: z.string().nullish(),\n\t\t}),\n\t),\n\tusage: openaiTokenUsageSchema,\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatChunkSchema = z.union([\n\tz.object({\n\t\tid: z.string().nullish(),\n\t\tcreated: z.number().nullish(),\n\t\tmodel: z.string().nullish(),\n\t\tchoices: z.array(\n\t\t\tz.object({\n\t\t\t\tdelta: z\n\t\t\t\t\t.object({\n\t\t\t\t\t\trole: z.enum([\"assistant\"]).nullish(),\n\t\t\t\t\t\tcontent: z.string().nullish(),\n\t\t\t\t\t\tfunction_call: z\n\t\t\t\t\t\t\t.object({\n\t\t\t\t\t\t\t\tname: z.string().optional(),\n\t\t\t\t\t\t\t\targuments: z.string().optional(),\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t.nullish(),\n\t\t\t\t\t\ttool_calls: z\n\t\t\t\t\t\t\t.array(\n\t\t\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\t\t\tindex: z.number(),\n\t\t\t\t\t\t\t\t\tid: z.string().nullish(),\n\t\t\t\t\t\t\t\t\ttype: z.literal(\"function\").optional(),\n\t\t\t\t\t\t\t\t\tfunction: z.object({\n\t\t\t\t\t\t\t\t\t\tname: z.string().nullish(),\n\t\t\t\t\t\t\t\t\t\targuments: z.string().nullish(),\n\t\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t.nullish(),\n\t\t\t\t\t})\n\t\t\t\t\t.nullish(),\n\t\t\t\tlogprobs: z\n\t\t\t\t\t.object({\n\t\t\t\t\t\tcontent: z\n\t\t\t\t\t\t\t.array(\n\t\t\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\t\t\ttoken: z.string(),\n\t\t\t\t\t\t\t\t\tlogprob: z.number(),\n\t\t\t\t\t\t\t\t\ttop_logprobs: z.array(\n\t\t\t\t\t\t\t\t\t\tz.object({\n\t\t\t\t\t\t\t\t\t\t\ttoken: z.string(),\n\t\t\t\t\t\t\t\t\t\t\tlogprob: z.number(),\n\t\t\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t.nullable(),\n\t\t\t\t\t})\n\t\t\t\t\t.nullish(),\n\t\t\t\tfinish_reason: z.string().nullable().optional(),\n\t\t\t\tindex: z.number(),\n\t\t\t}),\n\t\t),\n\t\tusage: openaiTokenUsageSchema,\n\t}),\n\topenaiErrorDataSchema,\n]);\n\nfunction isReasoningModel(modelId: string) {\n\treturn (\n\t\tmodelId === \"o1\" ||\n\t\tmodelId.startsWith(\"o1-\") ||\n\t\tmodelId === \"o3\" ||\n\t\tmodelId.startsWith(\"o3-\")\n\t);\n}\n\nfunction isAudioModel(modelId: string) {\n\treturn modelId.startsWith(\"gpt-4o-audio-preview\");\n}\n","import {\n  LanguageModelV1Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { convertUint8ArrayToBase64 } from '@ai-sdk/provider-utils';\nimport { OpenAIChatPrompt } from './openai-chat-prompt';\n\nexport function convertToOpenAIChatMessages({\n  prompt,\n  useLegacyFunctionCalling = false,\n}: {\n  prompt: LanguageModelV1Prompt;\n  useLegacyFunctionCalling?: boolean;\n}): OpenAIChatPrompt {\n  const messages: OpenAIChatPrompt = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        messages.push({ role: 'system', content });\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({ role: 'user', content: content[0].text });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map(part => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'image': {\n                return {\n                  type: 'image_url',\n                  image_url: {\n                    url:\n                      part.image instanceof URL\n                        ? part.image.toString()\n                        : `data:${\n                            part.mimeType ?? 'image/jpeg'\n                          };base64,${convertUint8ArrayToBase64(part.image)}`,\n\n                    // OpenAI specific extension: image detail\n                    detail: part.providerMetadata?.openai?.imageDetail,\n                  },\n                };\n              }\n              case 'file': {\n                if (part.data instanceof URL) {\n                  throw new UnsupportedFunctionalityError({\n                    functionality:\n                      \"'File content parts with URL data' functionality not supported.\",\n                  });\n                }\n\n                switch (part.mimeType) {\n                  case 'audio/wav': {\n                    return {\n                      type: 'input_audio',\n                      input_audio: { data: part.data, format: 'wav' },\n                    };\n                  }\n                  case 'audio/mp3':\n                  case 'audio/mpeg': {\n                    return {\n                      type: 'input_audio',\n                      input_audio: { data: part.data, format: 'mp3' },\n                    };\n                  }\n\n                  default: {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: `File content part type ${part.mimeType} in user messages`,\n                    });\n                  }\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args),\n                },\n              });\n              break;\n            }\n            default: {\n              const _exhaustiveCheck: never = part;\n              throw new Error(`Unsupported part: ${_exhaustiveCheck}`);\n            }\n          }\n        }\n\n        if (useLegacyFunctionCalling) {\n          if (toolCalls.length > 1) {\n            throw new UnsupportedFunctionalityError({\n              functionality:\n                'useLegacyFunctionCalling with multiple tool calls in one message',\n            });\n          }\n\n          messages.push({\n            role: 'assistant',\n            content: text,\n            function_call:\n              toolCalls.length > 0 ? toolCalls[0].function : undefined,\n          });\n        } else {\n          messages.push({\n            role: 'assistant',\n            content: text,\n            tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n          });\n        }\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          if (useLegacyFunctionCalling) {\n            messages.push({\n              role: 'function',\n              name: toolResponse.toolName,\n              content: JSON.stringify(toolResponse.result),\n            });\n          } else {\n            messages.push({\n              role: 'tool',\n              tool_call_id: toolResponse.toolCallId,\n              content: JSON.stringify(toolResponse.result),\n            });\n          }\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return messages;\n}\n","import { LanguageModelV1LogProbs } from '@ai-sdk/provider';\n\ntype OpenAIChatLogProbs = {\n  content:\n    | {\n        token: string;\n        logprob: number;\n        top_logprobs:\n          | {\n              token: string;\n              logprob: number;\n            }[]\n          | null;\n      }[]\n    | null;\n};\n\nexport function mapOpenAIChatLogProbsOutput(\n  logprobs: OpenAIChatLogProbs | null | undefined,\n): LanguageModelV1LogProbs | undefined {\n  return (\n    logprobs?.content?.map(({ token, logprob, top_logprobs }) => ({\n      token,\n      logprob,\n      topLogprobs: top_logprobs\n        ? top_logprobs.map(({ token, logprob }) => ({\n            token,\n            logprob,\n          }))\n        : [],\n    })) ?? undefined\n  );\n}\n","import { LanguageModelV1FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV1FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z } from 'zod';\nimport { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\n\nexport const openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAIErrorData = z.infer<typeof openaiErrorDataSchema>;\n\nexport const openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import {\n  JSONSchema7,\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function prepareTools({\n  mode,\n  useLegacyFunctionCalling = false,\n  structuredOutputs,\n}: {\n  mode: Parameters<LanguageModelV1['doGenerate']>[0]['mode'] & {\n    type: 'regular';\n  };\n  useLegacyFunctionCalling: boolean | undefined;\n  structuredOutputs: boolean;\n}): {\n  tools?: {\n    type: 'function';\n    function: {\n      name: string;\n      description: string | undefined;\n      parameters: JSONSchema7;\n      strict?: boolean;\n    };\n  }[];\n  tool_choice?:\n    | 'auto'\n    | 'none'\n    | 'required'\n    | { type: 'function'; function: { name: string } };\n\n  // legacy support\n  functions?: {\n    name: string;\n    description: string | undefined;\n    parameters: JSONSchema7;\n  }[];\n  function_call?: { name: string };\n\n  toolWarnings: LanguageModelV1CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  const tools = mode.tools?.length ? mode.tools : undefined;\n\n  const toolWarnings: LanguageModelV1CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, tool_choice: undefined, toolWarnings };\n  }\n\n  const toolChoice = mode.toolChoice;\n\n  if (useLegacyFunctionCalling) {\n    const openaiFunctions: Array<{\n      name: string;\n      description: string | undefined;\n      parameters: JSONSchema7;\n    }> = [];\n\n    for (const tool of tools) {\n      if (tool.type === 'provider-defined') {\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n      } else {\n        openaiFunctions.push({\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n        });\n      }\n    }\n\n    if (toolChoice == null) {\n      return {\n        functions: openaiFunctions,\n        function_call: undefined,\n        toolWarnings,\n      };\n    }\n\n    const type = toolChoice.type;\n\n    switch (type) {\n      case 'auto':\n      case 'none':\n      case undefined:\n        return {\n          functions: openaiFunctions,\n          function_call: undefined,\n          toolWarnings,\n        };\n      case 'required':\n        throw new UnsupportedFunctionalityError({\n          functionality: 'useLegacyFunctionCalling and toolChoice: required',\n        });\n      default:\n        return {\n          functions: openaiFunctions,\n          function_call: { name: toolChoice.toolName },\n          toolWarnings,\n        };\n    }\n  }\n\n  const openaiTools: Array<{\n    type: 'function';\n    function: {\n      name: string;\n      description: string | undefined;\n      parameters: JSONSchema7;\n      strict: boolean | undefined;\n    };\n  }> = [];\n\n  for (const tool of tools) {\n    if (tool.type === 'provider-defined') {\n      toolWarnings.push({ type: 'unsupported-tool', tool });\n    } else {\n      openaiTools.push({\n        type: 'function',\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n          strict: structuredOutputs ? true : undefined,\n        },\n      });\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, tool_choice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, tool_choice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        tool_choice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import {\n  LanguageModelV1,\n  LanguageModelV1CallWarning,\n  LanguageModelV1FinishReason,\n  LanguageModelV1LogProbs,\n  LanguageModelV1StreamPart,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { convertToOpenAICompletionPrompt } from './convert-to-openai-completion-prompt';\nimport { mapOpenAICompletionLogProbs } from './map-openai-completion-logprobs';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAICompletionModelId,\n  OpenAICompletionSettings,\n} from './openai-completion-settings';\nimport {\n  openaiErrorDataSchema,\n  openaiFailedResponseHandler,\n} from './openai-error';\nimport { getResponseMetadata } from './get-response-metadata';\n\ntype OpenAICompletionConfig = {\n  provider: string;\n  compatibility: 'strict' | 'compatible';\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAICompletionLanguageModel implements LanguageModelV1 {\n  readonly specificationVersion = 'v1';\n  readonly defaultObjectGenerationMode = undefined;\n\n  readonly modelId: OpenAICompletionModelId;\n  readonly settings: OpenAICompletionSettings;\n\n  private readonly config: OpenAICompletionConfig;\n\n  constructor(\n    modelId: OpenAICompletionModelId,\n    settings: OpenAICompletionSettings,\n    config: OpenAICompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private getArgs({\n    mode,\n    inputFormat,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    seed,\n  }: Parameters<LanguageModelV1['doGenerate']>[0]) {\n    const type = mode.type;\n\n    const warnings: LanguageModelV1CallWarning[] = [];\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompletionPrompt({ prompt, inputFormat });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      echo: this.settings.echo,\n      logit_bias: this.settings.logitBias,\n      logprobs:\n        typeof this.settings.logprobs === 'number'\n          ? this.settings.logprobs\n          : typeof this.settings.logprobs === 'boolean'\n          ? this.settings.logprobs\n            ? 0\n            : undefined\n          : undefined,\n      suffix: this.settings.suffix,\n      user: this.settings.user,\n\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      seed,\n\n      // prompt:\n      prompt: completionPrompt,\n\n      // stop sequences:\n      stop: stop.length > 0 ? stop : undefined,\n    };\n\n    switch (type) {\n      case 'regular': {\n        if (mode.tools?.length) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'tools',\n          });\n        }\n\n        if (mode.toolChoice) {\n          throw new UnsupportedFunctionalityError({\n            functionality: 'toolChoice',\n          });\n        }\n\n        return { args: baseArgs, warnings };\n      }\n\n      case 'object-json': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-json mode',\n        });\n      }\n\n      case 'object-tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'object-tool mode',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV1['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doGenerate']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n\n    return {\n      text: choice.text,\n      usage: {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens,\n      },\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      logprobs: mapOpenAICompletionLogProbs(choice.logprobs),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      response: getResponseMetadata(response),\n      warnings,\n      request: { body: JSON.stringify(args) },\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV1['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV1['doStream']>>> {\n    const { args, warnings } = this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n\n      // only include stream_options when in strict compatibility mode:\n      stream_options:\n        this.config.compatibility === 'strict'\n          ? { include_usage: true }\n          : undefined,\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiCompletionChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const { prompt: rawPrompt, ...rawSettings } = args;\n\n    let finishReason: LanguageModelV1FinishReason = 'unknown';\n    let usage: { promptTokens: number; completionTokens: number } = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN,\n    };\n    let logprobs: LanguageModelV1LogProbs;\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiCompletionChunkSchema>>,\n          LanguageModelV1StreamPart\n        >({\n          transform(chunk, controller) {\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens,\n              };\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.text != null) {\n              controller.enqueue({\n                type: 'text-delta',\n                textDelta: choice.text,\n              });\n            }\n\n            const mappedLogprobs = mapOpenAICompletionLogProbs(\n              choice?.logprobs,\n            );\n            if (mappedLogprobs?.length) {\n              if (logprobs === undefined) logprobs = [];\n              logprobs.push(...mappedLogprobs);\n            }\n          },\n\n          flush(controller) {\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              logprobs,\n              usage,\n            });\n          },\n        }),\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body: JSON.stringify(body) },\n    };\n  }\n}\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      text: z.string(),\n      finish_reason: z.string(),\n      logprobs: z\n        .object({\n          tokens: z.array(z.string()),\n          token_logprobs: z.array(z.number()),\n          top_logprobs: z.array(z.record(z.string(), z.number())).nullable(),\n        })\n        .nullish(),\n    }),\n  ),\n  usage: z.object({\n    prompt_tokens: z.number(),\n    completion_tokens: z.number(),\n  }),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionChunkSchema = z.union([\n  z.object({\n    id: z.string().nullish(),\n    created: z.number().nullish(),\n    model: z.string().nullish(),\n    choices: z.array(\n      z.object({\n        text: z.string(),\n        finish_reason: z.string().nullish(),\n        index: z.number(),\n        logprobs: z\n          .object({\n            tokens: z.array(z.string()),\n            token_logprobs: z.array(z.number()),\n            top_logprobs: z.array(z.record(z.string(), z.number())).nullable(),\n          })\n          .nullish(),\n      }),\n    ),\n    usage: z\n      .object({\n        prompt_tokens: z.number(),\n        completion_tokens: z.number(),\n      })\n      .nullish(),\n  }),\n  openaiErrorDataSchema,\n]);\n","import {\n  InvalidPromptError,\n  LanguageModelV1Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompletionPrompt({\n  prompt,\n  inputFormat,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV1Prompt;\n  inputFormat: 'prompt' | 'messages';\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // When the user supplied a prompt input, we don't transform it:\n  if (\n    inputFormat === 'prompt' &&\n    prompt.length === 1 &&\n    prompt[0].role === 'user' &&\n    prompt[0].content.length === 1 &&\n    prompt[0].content[0].type === 'text'\n  ) {\n    return { prompt: prompt[0].content[0].text };\n  }\n\n  // otherwise transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'image': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'images',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","import { LanguageModelV1LogProbs } from '@ai-sdk/provider';\n\ntype OpenAICompletionLogProps = {\n  tokens: string[];\n  token_logprobs: number[];\n  top_logprobs: Record<string, number>[] | null;\n};\n\nexport function mapOpenAICompletionLogProbs(\n  logprobs: OpenAICompletionLogProps | null | undefined,\n): LanguageModelV1LogProbs | undefined {\n  return logprobs?.tokens.map((token, index) => ({\n    token,\n    logprob: logprobs.token_logprobs[index],\n    topLogprobs: logprobs.top_logprobs\n      ? Object.entries(logprobs.top_logprobs[index]).map(\n          ([token, logprob]) => ({\n            token,\n            logprob,\n          }),\n        )\n      : [],\n  }));\n}\n","import {\n  EmbeddingModelV1,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { OpenAIConfig } from './openai-config';\nimport {\n  OpenAIEmbeddingModelId,\n  OpenAIEmbeddingSettings,\n} from './openai-embedding-settings';\nimport { openaiFailedResponseHandler } from './openai-error';\n\nexport class OpenAIEmbeddingModel implements EmbeddingModelV1<string> {\n  readonly specificationVersion = 'v1';\n  readonly modelId: OpenAIEmbeddingModelId;\n\n  private readonly config: OpenAIConfig;\n  private readonly settings: OpenAIEmbeddingSettings;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  get maxEmbeddingsPerCall(): number {\n    return this.settings.maxEmbeddingsPerCall ?? 2048;\n  }\n\n  get supportsParallelCalls(): boolean {\n    return this.settings.supportsParallelCalls ?? true;\n  }\n\n  constructor(\n    modelId: OpenAIEmbeddingModelId,\n    settings: OpenAIEmbeddingSettings,\n    config: OpenAIConfig,\n  ) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n  }: Parameters<EmbeddingModelV1<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV1<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: this.settings.dimensions,\n        user: this.settings.user,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      rawResponse: { headers: responseHeaders },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n","import { ImageModelV1 } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod';\nimport { OpenAIConfig } from './openai-config';\nimport { openaiFailedResponseHandler } from './openai-error';\n\nexport type OpenAIImageModelId = 'dall-e-3' | 'dall-e-2' | (string & {});\n\nexport class OpenAIImageModel implements ImageModelV1 {\n  readonly specificationVersion = 'v1';\n  readonly modelId: OpenAIImageModelId;\n\n  private readonly config: OpenAIConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(modelId: OpenAIImageModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV1['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV1['doGenerate']>>\n  > {\n    const { value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/images/generations',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(providerOptions.openai ?? {}),\n        response_format: 'b64_json',\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      images: response.data.map(item => item.b64_json),\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiImageResponseSchema = z.object({\n  data: z.array(z.object({ b64_json: z.string() })),\n});\n"],"mappings":";AAMA;AAAA,EAEE;AAAA,EACA;AAAA,OACK;;;ACVP;AAAA,EACC;AAAA,EAOA,iCAAAA;AAAA,OACM;AACP;AAAA,EAGC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACM;AACP,SAAS,KAAAC,UAAS;;;ACpBlB;AAAA,EAEE;AAAA,OACK;AACP,SAAS,iCAAiC;AAGnC,SAAS,4BAA4B;AAAA,EAC1C;AAAA,EACA,2BAA2B;AAC7B,GAGqB;AACnB,QAAM,WAA6B,CAAC;AAEpC,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK,UAAU;AACb,iBAAS,KAAK,EAAE,MAAM,UAAU,QAAQ,CAAC;AACzC;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,YAAI,QAAQ,WAAW,KAAK,QAAQ,CAAC,EAAE,SAAS,QAAQ;AACtD,mBAAS,KAAK,EAAE,MAAM,QAAQ,SAAS,QAAQ,CAAC,EAAE,KAAK,CAAC;AACxD;AAAA,QACF;AAEA,iBAAS,KAAK;AAAA,UACZ,MAAM;AAAA,UACN,SAAS,QAAQ,IAAI,UAAQ;AA/BvC;AAgCY,oBAAQ,KAAK,MAAM;AAAA,cACjB,KAAK,QAAQ;AACX,uBAAO,EAAE,MAAM,QAAQ,MAAM,KAAK,KAAK;AAAA,cACzC;AAAA,cACA,KAAK,SAAS;AACZ,uBAAO;AAAA,kBACL,MAAM;AAAA,kBACN,WAAW;AAAA,oBACT,KACE,KAAK,iBAAiB,MAClB,KAAK,MAAM,SAAS,IACpB,SACE,UAAK,aAAL,YAAiB,YACnB,WAAW,0BAA0B,KAAK,KAAK,CAAC;AAAA;AAAA,oBAGtD,SAAQ,gBAAK,qBAAL,mBAAuB,WAAvB,mBAA+B;AAAA,kBACzC;AAAA,gBACF;AAAA,cACF;AAAA,cACA,KAAK,QAAQ;AACX,oBAAI,KAAK,gBAAgB,KAAK;AAC5B,wBAAM,IAAI,8BAA8B;AAAA,oBACtC,eACE;AAAA,kBACJ,CAAC;AAAA,gBACH;AAEA,wBAAQ,KAAK,UAAU;AAAA,kBACrB,KAAK,aAAa;AAChB,2BAAO;AAAA,sBACL,MAAM;AAAA,sBACN,aAAa,EAAE,MAAM,KAAK,MAAM,QAAQ,MAAM;AAAA,oBAChD;AAAA,kBACF;AAAA,kBACA,KAAK;AAAA,kBACL,KAAK,cAAc;AACjB,2BAAO;AAAA,sBACL,MAAM;AAAA,sBACN,aAAa,EAAE,MAAM,KAAK,MAAM,QAAQ,MAAM;AAAA,oBAChD;AAAA,kBACF;AAAA,kBAEA,SAAS;AACP,0BAAM,IAAI,8BAA8B;AAAA,sBACtC,eAAe,0BAA0B,KAAK,QAAQ;AAAA,oBACxD,CAAC;AAAA,kBACH;AAAA,gBACF;AAAA,cACF;AAAA,YACF;AAAA,UACF,CAAC;AAAA,QACH,CAAC;AAED;AAAA,MACF;AAAA,MAEA,KAAK,aAAa;AAChB,YAAI,OAAO;AACX,cAAM,YAID,CAAC;AAEN,mBAAW,QAAQ,SAAS;AAC1B,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,sBAAQ,KAAK;AACb;AAAA,YACF;AAAA,YACA,KAAK,aAAa;AAChB,wBAAU,KAAK;AAAA,gBACb,IAAI,KAAK;AAAA,gBACT,MAAM;AAAA,gBACN,UAAU;AAAA,kBACR,MAAM,KAAK;AAAA,kBACX,WAAW,KAAK,UAAU,KAAK,IAAI;AAAA,gBACrC;AAAA,cACF,CAAC;AACD;AAAA,YACF;AAAA,YACA,SAAS;AACP,oBAAM,mBAA0B;AAChC,oBAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,YACzD;AAAA,UACF;AAAA,QACF;AAEA,YAAI,0BAA0B;AAC5B,cAAI,UAAU,SAAS,GAAG;AACxB,kBAAM,IAAI,8BAA8B;AAAA,cACtC,eACE;AAAA,YACJ,CAAC;AAAA,UACH;AAEA,mBAAS,KAAK;AAAA,YACZ,MAAM;AAAA,YACN,SAAS;AAAA,YACT,eACE,UAAU,SAAS,IAAI,UAAU,CAAC,EAAE,WAAW;AAAA,UACnD,CAAC;AAAA,QACH,OAAO;AACL,mBAAS,KAAK;AAAA,YACZ,MAAM;AAAA,YACN,SAAS;AAAA,YACT,YAAY,UAAU,SAAS,IAAI,YAAY;AAAA,UACjD,CAAC;AAAA,QACH;AAEA;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,mBAAW,gBAAgB,SAAS;AAClC,cAAI,0BAA0B;AAC5B,qBAAS,KAAK;AAAA,cACZ,MAAM;AAAA,cACN,MAAM,aAAa;AAAA,cACnB,SAAS,KAAK,UAAU,aAAa,MAAM;AAAA,YAC7C,CAAC;AAAA,UACH,OAAO;AACL,qBAAS,KAAK;AAAA,cACZ,MAAM;AAAA,cACN,cAAc,aAAa;AAAA,cAC3B,SAAS,KAAK,UAAU,aAAa,MAAM;AAAA,YAC7C,CAAC;AAAA,UACH;AAAA,QACF;AACA;AAAA,MACF;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;;;AC5JO,SAAS,4BACd,UACqC;AAnBvC;AAoBE,UACE,gDAAU,YAAV,mBAAmB,IAAI,CAAC,EAAE,OAAO,SAAS,aAAa,OAAO;AAAA,IAC5D;AAAA,IACA;AAAA,IACA,aAAa,eACT,aAAa,IAAI,CAAC,EAAE,OAAAC,QAAO,SAAAC,SAAQ,OAAO;AAAA,MACxC,OAAAD;AAAA,MACA,SAAAC;AAAA,IACF,EAAE,IACF,CAAC;AAAA,EACP,QATA,YASO;AAEX;;;AC9BO,SAAS,sBACd,cAC6B;AAC7B,UAAQ,cAAc;AAAA,IACpB,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AAAA,IACL,KAAK;AACH,aAAO;AAAA,IACT;AACE,aAAO;AAAA,EACX;AACF;;;AClBA,SAAS,SAAS;AAClB,SAAS,sCAAsC;AAExC,IAAM,wBAAwB,EAAE,OAAO;AAAA,EAC5C,OAAO,EAAE,OAAO;AAAA,IACd,SAAS,EAAE,OAAO;AAAA;AAAA;AAAA;AAAA,IAKlB,MAAM,EAAE,OAAO,EAAE,QAAQ;AAAA,IACzB,OAAO,EAAE,IAAI,EAAE,QAAQ;AAAA,IACvB,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,QAAQ;AAAA,EAClD,CAAC;AACH,CAAC;AAIM,IAAM,8BAA8B,+BAA+B;AAAA,EACxE,aAAa;AAAA,EACb,gBAAgB,UAAQ,KAAK,MAAM;AACrC,CAAC;;;ACrBM,SAAS,oBAAoB;AAAA,EAClC;AAAA,EACA;AAAA,EACA;AACF,GAIG;AACD,SAAO;AAAA,IACL,IAAI,kBAAM;AAAA,IACV,SAAS,wBAAS;AAAA,IAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI;AAAA,EAC1D;AACF;;;ACdA;AAAA,EAIE,iCAAAC;AAAA,OACK;AAEA,SAAS,aAAa;AAAA,EAC3B;AAAA,EACA,2BAA2B;AAAA,EAC3B;AACF,GA+BE;AA1CF;AA4CE,QAAM,UAAQ,UAAK,UAAL,mBAAY,UAAS,KAAK,QAAQ;AAEhD,QAAM,eAA6C,CAAC;AAEpD,MAAI,SAAS,MAAM;AACjB,WAAO,EAAE,OAAO,QAAW,aAAa,QAAW,aAAa;AAAA,EAClE;AAEA,QAAM,aAAa,KAAK;AAExB,MAAI,0BAA0B;AAC5B,UAAM,kBAID,CAAC;AAEN,eAAW,QAAQ,OAAO;AACxB,UAAI,KAAK,SAAS,oBAAoB;AACpC,qBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AAAA,MACtD,OAAO;AACL,wBAAgB,KAAK;AAAA,UACnB,MAAM,KAAK;AAAA,UACX,aAAa,KAAK;AAAA,UAClB,YAAY,KAAK;AAAA,QACnB,CAAC;AAAA,MACH;AAAA,IACF;AAEA,QAAI,cAAc,MAAM;AACtB,aAAO;AAAA,QACL,WAAW;AAAA,QACX,eAAe;AAAA,QACf;AAAA,MACF;AAAA,IACF;AAEA,UAAMC,QAAO,WAAW;AAExB,YAAQA,OAAM;AAAA,MACZ,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AACH,eAAO;AAAA,UACL,WAAW;AAAA,UACX,eAAe;AAAA,UACf;AAAA,QACF;AAAA,MACF,KAAK;AACH,cAAM,IAAID,+BAA8B;AAAA,UACtC,eAAe;AAAA,QACjB,CAAC;AAAA,MACH;AACE,eAAO;AAAA,UACL,WAAW;AAAA,UACX,eAAe,EAAE,MAAM,WAAW,SAAS;AAAA,UAC3C;AAAA,QACF;AAAA,IACJ;AAAA,EACF;AAEA,QAAM,cAQD,CAAC;AAEN,aAAW,QAAQ,OAAO;AACxB,QAAI,KAAK,SAAS,oBAAoB;AACpC,mBAAa,KAAK,EAAE,MAAM,oBAAoB,KAAK,CAAC;AAAA,IACtD,OAAO;AACL,kBAAY,KAAK;AAAA,QACf,MAAM;AAAA,QACN,UAAU;AAAA,UACR,MAAM,KAAK;AAAA,UACX,aAAa,KAAK;AAAA,UAClB,YAAY,KAAK;AAAA,UACjB,QAAQ,oBAAoB,OAAO;AAAA,QACrC;AAAA,MACF,CAAC;AAAA,IACH;AAAA,EACF;AAEA,MAAI,cAAc,MAAM;AACtB,WAAO,EAAE,OAAO,aAAa,aAAa,QAAW,aAAa;AAAA,EACpE;AAEA,QAAM,OAAO,WAAW;AAExB,UAAQ,MAAM;AAAA,IACZ,KAAK;AAAA,IACL,KAAK;AAAA,IACL,KAAK;AACH,aAAO,EAAE,OAAO,aAAa,aAAa,MAAM,aAAa;AAAA,IAC/D,KAAK;AACH,aAAO;AAAA,QACL,OAAO;AAAA,QACP,aAAa;AAAA,UACX,MAAM;AAAA,UACN,UAAU;AAAA,YACR,MAAM,WAAW;AAAA,UACnB;AAAA,QACF;AAAA,QACA;AAAA,MACF;AAAA,IACF,SAAS;AACP,YAAM,mBAA0B;AAChC,YAAM,IAAIA,+BAA8B;AAAA,QACtC,eAAe,iCAAiC,gBAAgB;AAAA,MAClE,CAAC;AAAA,IACH;AAAA,EACF;AACF;;;ANxHO,IAAM,0BAAN,MAAyD;AAAA,EAQ/D,YACC,SACA,UACA,QACC;AAXF,SAAS,uBAAuB;AAY/B,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,SAAS;AAAA,EACf;AAAA,EAEA,IAAI,4BAAqC;AA1D1C;AA2DE,YAAO,UAAK,SAAS,sBAAd,YAAmC;AAAA,EAC3C;AAAA,EAEA,IAAI,8BAA8B;AAEjC,QAAI,aAAa,KAAK,OAAO,GAAG;AAC/B,aAAO;AAAA,IACR;AAEA,WAAO,KAAK,4BAA4B,SAAS;AAAA,EAClD;AAAA,EAEA,IAAI,WAAmB;AACtB,WAAO,KAAK,OAAO;AAAA,EACpB;AAAA,EAEA,IAAI,oBAA6B;AAEhC,WAAO,CAAC,KAAK,SAAS;AAAA,EACvB;AAAA,EAEQ,QAAQ;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACD,GAAiD;AA7FlD;AA8FE,UAAM,OAAO,KAAK;AAElB,UAAM,WAAyC,CAAC;AAEhD,QAAI,QAAQ,MAAM;AACjB,eAAS,KAAK;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,MACV,CAAC;AAAA,IACF;AAEA,SACC,iDAAgB,UAAS,UACzB,eAAe,UAAU,QACzB,CAAC,KAAK,2BACL;AACD,eAAS,KAAK;AAAA,QACb,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SACC;AAAA,MACF,CAAC;AAAA,IACF;AAEA,UAAM,2BAA2B,KAAK,SAAS;AAE/C,QAAI,4BAA4B,KAAK,SAAS,sBAAsB,MAAM;AACzE,YAAM,IAAIE,+BAA8B;AAAA,QACvC,eAAe;AAAA,MAChB,CAAC;AAAA,IACF;AAEA,QAAI,4BAA4B,KAAK,2BAA2B;AAC/D,YAAM,IAAIA,+BAA8B;AAAA,QACvC,eAAe;AAAA,MAChB,CAAC;AAAA,IACF;AAEA,UAAM,WAAW;AAAA;AAAA,MAEhB,OAAO,KAAK;AAAA;AAAA,MAGZ,YAAY,KAAK,SAAS;AAAA,MAC1B,UACC,KAAK,SAAS,aAAa,QAC3B,OAAO,KAAK,SAAS,aAAa,WAC/B,OACA;AAAA,MACJ,cACC,OAAO,KAAK,SAAS,aAAa,WAC/B,KAAK,SAAS,WACd,OAAO,KAAK,SAAS,aAAa,YACjC,KAAK,SAAS,WACb,IACA,SACD;AAAA,MACL,MAAM,KAAK,SAAS;AAAA,MACpB,qBAAqB,KAAK,SAAS;AAAA;AAAA,MAGnC,YAAY;AAAA,MACZ;AAAA,MACA,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB,kBACC,iDAAgB,UAAS,SACtB,KAAK,6BAA6B,eAAe,UAAU,OAC1D;AAAA,QACA,MAAM;AAAA,QACN,aAAa;AAAA,UACZ,QAAQ,eAAe;AAAA,UACvB,QAAQ;AAAA,UACR,OAAM,oBAAe,SAAf,YAAuB;AAAA,UAC7B,aAAa,eAAe;AAAA,QAC7B;AAAA,MACD,IACC,EAAE,MAAM,cAAc,IACvB;AAAA,MACJ,MAAM;AAAA,MACN;AAAA;AAAA,MAGA,wBAAuB,0DAAkB,WAAlB,mBAA0B;AAAA,MACjD,QAAO,0DAAkB,WAAlB,mBAA0B;AAAA,MACjC,WAAU,0DAAkB,WAAlB,mBAA0B;AAAA,MACpC,aAAY,0DAAkB,WAAlB,mBAA0B;AAAA,MACtC,mBACC,gEAAkB,WAAlB,mBAA0B,oBAA1B,YACA,KAAK,SAAS;AAAA;AAAA,MAGf,UAAU,4BAA4B;AAAA,QACrC;AAAA,QACA;AAAA,MACD,CAAC;AAAA,IACF;AAGA,QAAI,iBAAiB,KAAK,OAAO,GAAG;AACnC,eAAS,cAAc;AACvB,eAAS,QAAQ;AACjB,eAAS,oBAAoB;AAC7B,eAAS,mBAAmB;AAAA,IAC7B;AAEA,YAAQ,MAAM;AAAA,MACb,KAAK,WAAW;AACf,cAAM,EAAE,OAAO,aAAa,WAAW,eAAe,aAAa,IAClE,aAAa;AAAA,UACZ;AAAA,UACA;AAAA,UACA,mBAAmB,KAAK;AAAA,QACzB,CAAC;AAEF,eAAO;AAAA,UACN,MAAM;AAAA,YACL,GAAG;AAAA,YACH;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,UACD;AAAA,UACA,UAAU,CAAC,GAAG,UAAU,GAAG,YAAY;AAAA,QACxC;AAAA,MACD;AAAA,MAEA,KAAK,eAAe;AACnB,eAAO;AAAA,UACN,MAAM;AAAA,YACL,GAAG;AAAA,YACH,iBACC,KAAK,6BAA6B,KAAK,UAAU,OAC9C;AAAA,cACA,MAAM;AAAA,cACN,aAAa;AAAA,gBACZ,QAAQ,KAAK;AAAA,gBACb,QAAQ;AAAA,gBACR,OAAM,UAAK,SAAL,YAAa;AAAA,gBACnB,aAAa,KAAK;AAAA,cACnB;AAAA,YACD,IACC,EAAE,MAAM,cAAc;AAAA,UAC3B;AAAA,UACA;AAAA,QACD;AAAA,MACD;AAAA,MAEA,KAAK,eAAe;AACnB,eAAO;AAAA,UACN,MAAM,2BACH;AAAA,YACA,GAAG;AAAA,YACH,eAAe;AAAA,cACd,MAAM,KAAK,KAAK;AAAA,YACjB;AAAA,YACA,WAAW;AAAA,cACV;AAAA,gBACC,MAAM,KAAK,KAAK;AAAA,gBAChB,aAAa,KAAK,KAAK;AAAA,gBACvB,YAAY,KAAK,KAAK;AAAA,cACvB;AAAA,YACD;AAAA,UACD,IACC;AAAA,YACA,GAAG;AAAA,YACH,aAAa;AAAA,cACZ,MAAM;AAAA,cACN,UAAU,EAAE,MAAM,KAAK,KAAK,KAAK;AAAA,YAClC;AAAA,YACA,OAAO;AAAA,cACN;AAAA,gBACC,MAAM;AAAA,gBACN,UAAU;AAAA,kBACT,MAAM,KAAK,KAAK;AAAA,kBAChB,aAAa,KAAK,KAAK;AAAA,kBACvB,YAAY,KAAK,KAAK;AAAA,kBACtB,QAAQ,KAAK,4BAA4B,OAAO;AAAA,gBACjD;AAAA,cACD;AAAA,YACD;AAAA,UACD;AAAA,UACF;AAAA,QACD;AAAA,MACD;AAAA,MAEA,SAAS;AACR,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACxD;AAAA,IACD;AAAA,EACD;AAAA,EAEA,MAAM,WACL,SAC8D;AAlShE;AAmSE,UAAM,EAAE,MAAM,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAErD,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;AAAA,MAChE,KAAK,KAAK,OAAO,IAAI;AAAA,QACpB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MACf,CAAC;AAAA,MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,2BAA2B;AAAA,QAC1B;AAAA,MACD;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACpB,CAAC;AAED,UAAM,EAAE,UAAU,WAAW,GAAG,YAAY,IAAI;AAChD,UAAM,SAAS,SAAS,QAAQ,CAAC;AAEjC,QAAI;AACJ,UACC,oBAAS,UAAT,mBAAgB,8BAAhB,mBAA2C,qBAAoB,UAC/D,oBAAS,UAAT,mBAAgB,0BAAhB,mBAAuC,kBAAiB,MACvD;AACD,yBAAmB,EAAE,QAAQ,CAAC,EAAE;AAChC,YAAI,oBAAS,UAAT,mBAAgB,8BAAhB,mBAA2C,qBAAoB,MAAM;AACxE,yBAAiB,OAAO,mBACvB,oBAAS,UAAT,mBAAgB,8BAAhB,mBAA2C;AAAA,MAC7C;AACA,YAAI,oBAAS,UAAT,mBAAgB,0BAAhB,mBAAuC,kBAAiB,MAAM;AACjE,yBAAiB,OAAO,sBACvB,oBAAS,UAAT,mBAAgB,0BAAhB,mBAAuC;AAAA,MACzC;AAAA,IACD;AAEA,WAAO;AAAA,MACN,OAAM,YAAO,QAAQ,YAAf,YAA0B;AAAA,MAChC,WACC,KAAK,SAAS,4BAA4B,OAAO,QAAQ,gBACtD;AAAA,QACA;AAAA,UACC,cAAc;AAAA,UACd,YAAY,WAAW;AAAA,UACvB,UAAU,OAAO,QAAQ,cAAc;AAAA,UACvC,MAAM,OAAO,QAAQ,cAAc;AAAA,QACpC;AAAA,MACD,KACC,YAAO,QAAQ,eAAf,mBAA2B,IAAI,CAAC,aAAU;AAnVjD,YAAAC;AAmVqD;AAAA,UAC9C,cAAc;AAAA,UACd,aAAYA,MAAA,SAAS,OAAT,OAAAA,MAAe,WAAW;AAAA,UACtC,UAAU,SAAS,SAAS;AAAA,UAC5B,MAAM,SAAS,SAAS;AAAA,QACzB;AAAA;AAAA,MACH,cAAc,sBAAsB,OAAO,aAAa;AAAA,MACxD,OAAO;AAAA,QACN,eAAc,oBAAS,UAAT,mBAAgB,kBAAhB,YAAiC;AAAA,QAC/C,mBAAkB,oBAAS,UAAT,mBAAgB,sBAAhB,YAAqC;AAAA,MACxD;AAAA,MACA,SAAS,EAAE,WAAW,YAAY;AAAA,MAClC,aAAa,EAAE,SAAS,gBAAgB;AAAA,MACxC,SAAS,EAAE,MAAM,KAAK,UAAU,IAAI,EAAE;AAAA,MACtC,UAAU,oBAAoB,QAAQ;AAAA,MACtC;AAAA,MACA,UAAU,4BAA4B,OAAO,QAAQ;AAAA,MACrD;AAAA,IACD;AAAA,EACD;AAAA,EAEA,MAAM,SACL,SAC4D;AAC5D,QAAI,KAAK,SAAS,mBAAmB;AACpC,YAAM,SAAS,MAAM,KAAK,WAAW,OAAO;AAC5C,YAAM,kBAAkB,IAAI,eAA0C;AAAA,QACrE,MAAM,YAAY;AACjB,qBAAW,QAAQ,EAAE,MAAM,qBAAqB,GAAG,OAAO,SAAS,CAAC;AACpE,cAAI,OAAO,MAAM;AAChB,uBAAW,QAAQ;AAAA,cAClB,MAAM;AAAA,cACN,WAAW,OAAO;AAAA,YACnB,CAAC;AAAA,UACF;AACA,cAAI,OAAO,WAAW;AACrB,uBAAW,YAAY,OAAO,WAAW;AACxC,yBAAW,QAAQ;AAAA,gBAClB,MAAM;AAAA,gBACN,GAAG;AAAA,cACJ,CAAC;AAAA,YACF;AAAA,UACD;AACA,qBAAW,QAAQ;AAAA,YAClB,MAAM;AAAA,YACN,cAAc,OAAO;AAAA,YACrB,OAAO,OAAO;AAAA,YACd,UAAU,OAAO;AAAA,YACjB,kBAAkB,OAAO;AAAA,UAC1B,CAAC;AACD,qBAAW,MAAM;AAAA,QAClB;AAAA,MACD,CAAC;AACD,aAAO;AAAA,QACN,QAAQ;AAAA,QACR,SAAS,OAAO;AAAA,QAChB,aAAa,OAAO;AAAA,QACpB,UAAU,OAAO;AAAA,MAClB;AAAA,IACD;AAEA,UAAM,EAAE,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAE/C,UAAM,OAAO;AAAA,MACZ,GAAG;AAAA,MACH,QAAQ;AAAA;AAAA,MAGR,gBACC,KAAK,OAAO,kBAAkB,WAC3B,EAAE,eAAe,KAAK,IACtB;AAAA,IACL;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAM,cAAc;AAAA,MAChE,KAAK,KAAK,OAAO,IAAI;AAAA,QACpB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MACf,CAAC;AAAA,MACD,SAAS,eAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,2BAA2B;AAAA,QAC1B;AAAA,MACD;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACpB,CAAC;AAED,UAAM,EAAE,UAAU,WAAW,GAAG,YAAY,IAAI;AAEhD,UAAM,YAQD,CAAC;AAEN,QAAI,eAA4C;AAChD,QAAI,QAGA;AAAA,MACH,cAAc;AAAA,MACd,kBAAkB;AAAA,IACnB;AACA,QAAI;AACJ,QAAI,eAAe;AAEnB,UAAM,EAAE,yBAAyB,IAAI,KAAK;AAE1C,QAAI;AACJ,WAAO;AAAA,MACN,QAAQ,SAAS;AAAA,QAChB,IAAI,gBAGF;AAAA,UACD,UAAU,OAAO,YAAY;AA5clC;AA8cM,gBAAI,CAAC,MAAM,SAAS;AACnB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACD;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACrB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACD;AAEA,gBAAI,cAAc;AACjB,6BAAe;AAEf,yBAAW,QAAQ;AAAA,gBAClB,MAAM;AAAA,gBACN,GAAG,oBAAoB,KAAK;AAAA,cAC7B,CAAC;AAAA,YACF;AAEA,gBAAI,MAAM,SAAS,MAAM;AACxB,sBAAQ;AAAA,gBACP,eAAc,WAAM,MAAM,kBAAZ,YAA6B;AAAA,gBAC3C,mBAAkB,WAAM,MAAM,sBAAZ,YAAiC;AAAA,cACpD;AAEA,oBAAM;AAAA,gBACL,2BAA2B;AAAA,gBAC3B,uBAAuB;AAAA,cACxB,IAAI,MAAM;AAEV,mBACC,iEAAwB,qBAAoB,SAC5C,yDAAoB,kBAAiB,MACpC;AACD,mCAAmB,EAAE,QAAQ,CAAC,EAAE;AAChC,qBAAI,iEAAwB,qBAAoB,MAAM;AACrD,mCAAiB,OAAO,kBACvB,iEAAwB;AAAA,gBAC1B;AACA,qBAAI,yDAAoB,kBAAiB,MAAM;AAC9C,mCAAiB,OAAO,qBACvB,yDAAoB;AAAA,gBACtB;AAAA,cACD;AAAA,YACD;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,iCAAQ,kBAAiB,MAAM;AAClC,6BAAe,sBAAsB,OAAO,aAAa;AAAA,YAC1D;AAEA,iBAAI,iCAAQ,UAAS,MAAM;AAC1B;AAAA,YACD;AAEA,kBAAM,QAAQ,OAAO;AAErB,gBAAI,MAAM,WAAW,MAAM;AAC1B,yBAAW,QAAQ;AAAA,gBAClB,MAAM;AAAA,gBACN,WAAW,MAAM;AAAA,cAClB,CAAC;AAAA,YACF;AAEA,kBAAM,iBAAiB;AAAA,cACtB,iCAAQ;AAAA,YACT;AACA,gBAAI,iDAAgB,QAAQ;AAC3B,kBAAI,aAAa,OAAW,YAAW,CAAC;AACxC,uBAAS,KAAK,GAAG,cAAc;AAAA,YAChC;AAEA,kBAAM,kBACL,4BAA4B,MAAM,iBAAiB,OAChD;AAAA,cACA;AAAA,gBACC,MAAM;AAAA,gBACN,IAAI,WAAW;AAAA,gBACf,UAAU,MAAM;AAAA,gBAChB,OAAO;AAAA,cACR;AAAA,YACD,IACC,MAAM;AAEV,gBAAI,mBAAmB,MAAM;AAC5B,yBAAW,iBAAiB,iBAAiB;AAC5C,sBAAM,QAAQ,cAAc;AAG5B,oBAAI,UAAU,KAAK,KAAK,MAAM;AAC7B,sBAAI,cAAc,SAAS,YAAY;AACtC,0BAAM,IAAI,yBAAyB;AAAA,sBAClC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACV,CAAC;AAAA,kBACF;AAEA,sBAAI,cAAc,MAAM,MAAM;AAC7B,0BAAM,IAAI,yBAAyB;AAAA,sBAClC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACV,CAAC;AAAA,kBACF;AAEA,wBAAI,mBAAc,aAAd,mBAAwB,SAAQ,MAAM;AACzC,0BAAM,IAAI,yBAAyB;AAAA,sBAClC,MAAM;AAAA,sBACN,SAAS;AAAA,oBACV,CAAC;AAAA,kBACF;AAEA,4BAAU,KAAK,IAAI;AAAA,oBAClB,IAAI,cAAc;AAAA,oBAClB,MAAM;AAAA,oBACN,UAAU;AAAA,sBACT,MAAM,cAAc,SAAS;AAAA,sBAC7B,YAAW,mBAAc,SAAS,cAAvB,YAAoC;AAAA,oBAChD;AAAA,oBACA,aAAa;AAAA,kBACd;AAEA,wBAAMC,YAAW,UAAU,KAAK;AAEhC,wBACC,KAAAA,UAAS,aAAT,mBAAmB,SAAQ,UAC3B,KAAAA,UAAS,aAAT,mBAAmB,cAAa,MAC/B;AAED,wBAAIA,UAAS,SAAS,UAAU,SAAS,GAAG;AAC3C,iCAAW,QAAQ;AAAA,wBAClB,MAAM;AAAA,wBACN,cAAc;AAAA,wBACd,YAAYA,UAAS;AAAA,wBACrB,UAAUA,UAAS,SAAS;AAAA,wBAC5B,eAAeA,UAAS,SAAS;AAAA,sBAClC,CAAC;AAAA,oBACF;AAIA,wBAAI,eAAeA,UAAS,SAAS,SAAS,GAAG;AAChD,iCAAW,QAAQ;AAAA,wBAClB,MAAM;AAAA,wBACN,cAAc;AAAA,wBACd,aAAY,KAAAA,UAAS,OAAT,YAAe,WAAW;AAAA,wBACtC,UAAUA,UAAS,SAAS;AAAA,wBAC5B,MAAMA,UAAS,SAAS;AAAA,sBACzB,CAAC;AACD,sBAAAA,UAAS,cAAc;AAAA,oBACxB;AAAA,kBACD;AAEA;AAAA,gBACD;AAGA,sBAAM,WAAW,UAAU,KAAK;AAEhC,oBAAI,SAAS,aAAa;AACzB;AAAA,gBACD;AAEA,sBAAI,mBAAc,aAAd,mBAAwB,cAAa,MAAM;AAC9C,2BAAS,SAAU,cAClB,yBAAc,aAAd,mBAAwB,cAAxB,YAAqC;AAAA,gBACvC;AAGA,2BAAW,QAAQ;AAAA,kBAClB,MAAM;AAAA,kBACN,cAAc;AAAA,kBACd,YAAY,SAAS;AAAA,kBACrB,UAAU,SAAS,SAAS;AAAA,kBAC5B,gBAAe,mBAAc,SAAS,cAAvB,YAAoC;AAAA,gBACpD,CAAC;AAGD,sBACC,cAAS,aAAT,mBAAmB,SAAQ,UAC3B,cAAS,aAAT,mBAAmB,cAAa,QAChC,eAAe,SAAS,SAAS,SAAS,GACzC;AACD,6BAAW,QAAQ;AAAA,oBAClB,MAAM;AAAA,oBACN,cAAc;AAAA,oBACd,aAAY,cAAS,OAAT,YAAe,WAAW;AAAA,oBACtC,UAAU,SAAS,SAAS;AAAA,oBAC5B,MAAM,SAAS,SAAS;AAAA,kBACzB,CAAC;AACD,2BAAS,cAAc;AAAA,gBACxB;AAAA,cACD;AAAA,YACD;AAAA,UACD;AAAA,UAEA,MAAM,YAAY;AAvpBvB;AAwpBM,uBAAW,QAAQ;AAAA,cAClB,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA,OAAO;AAAA,gBACN,eAAc,WAAM,iBAAN,YAAsB;AAAA,gBACpC,mBAAkB,WAAM,qBAAN,YAA0B;AAAA,cAC7C;AAAA,cACA,GAAI,oBAAoB,OAAO,EAAE,iBAAiB,IAAI,CAAC;AAAA,YACxD,CAAC;AAAA,UACF;AAAA,QACD,CAAC;AAAA,MACF;AAAA,MACA,SAAS,EAAE,WAAW,YAAY;AAAA,MAClC,aAAa,EAAE,SAAS,gBAAgB;AAAA,MACxC,SAAS,EAAE,MAAM,KAAK,UAAU,IAAI,EAAE;AAAA,MACtC;AAAA,IACD;AAAA,EACD;AACD;AAEA,IAAM,yBAAyBC,GAC7B,OAAO;AAAA,EACP,eAAeA,GAAE,OAAO,EAAE,QAAQ;AAAA,EAClC,mBAAmBA,GAAE,OAAO,EAAE,QAAQ;AAAA,EACtC,uBAAuBA,GACrB,OAAO;AAAA,IACP,eAAeA,GAAE,OAAO,EAAE,QAAQ;AAAA,EACnC,CAAC,EACA,QAAQ;AAAA,EACV,2BAA2BA,GACzB,OAAO;AAAA,IACP,kBAAkBA,GAAE,OAAO,EAAE,QAAQ;AAAA,EACtC,CAAC,EACA,QAAQ;AACX,CAAC,EACA,QAAQ;AAIV,IAAM,2BAA2BA,GAAE,OAAO;AAAA,EACzC,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,EACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,EAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;AAAA,EAC1B,SAASA,GAAE;AAAA,IACVA,GAAE,OAAO;AAAA,MACR,SAASA,GAAE,OAAO;AAAA,QACjB,MAAMA,GAAE,QAAQ,WAAW,EAAE,QAAQ;AAAA,QACrC,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,QAC5B,eAAeA,GACb,OAAO;AAAA,UACP,WAAWA,GAAE,OAAO;AAAA,UACpB,MAAMA,GAAE,OAAO;AAAA,QAChB,CAAC,EACA,QAAQ;AAAA,QACV,YAAYA,GACV;AAAA,UACAA,GAAE,OAAO;AAAA,YACR,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,YACvB,MAAMA,GAAE,QAAQ,UAAU;AAAA,YAC1B,UAAUA,GAAE,OAAO;AAAA,cAClB,MAAMA,GAAE,OAAO;AAAA,cACf,WAAWA,GAAE,OAAO;AAAA,YACrB,CAAC;AAAA,UACF,CAAC;AAAA,QACF,EACC,QAAQ;AAAA,MACX,CAAC;AAAA,MACD,OAAOA,GAAE,OAAO;AAAA,MAChB,UAAUA,GACR,OAAO;AAAA,QACP,SAASA,GACP;AAAA,UACAA,GAAE,OAAO;AAAA,YACR,OAAOA,GAAE,OAAO;AAAA,YAChB,SAASA,GAAE,OAAO;AAAA,YAClB,cAAcA,GAAE;AAAA,cACfA,GAAE,OAAO;AAAA,gBACR,OAAOA,GAAE,OAAO;AAAA,gBAChB,SAASA,GAAE,OAAO;AAAA,cACnB,CAAC;AAAA,YACF;AAAA,UACD,CAAC;AAAA,QACF,EACC,SAAS;AAAA,MACZ,CAAC,EACA,QAAQ;AAAA,MACV,eAAeA,GAAE,OAAO,EAAE,QAAQ;AAAA,IACnC,CAAC;AAAA,EACF;AAAA,EACA,OAAO;AACR,CAAC;AAID,IAAM,wBAAwBA,GAAE,MAAM;AAAA,EACrCA,GAAE,OAAO;AAAA,IACR,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,IACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,IAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;AAAA,IAC1B,SAASA,GAAE;AAAA,MACVA,GAAE,OAAO;AAAA,QACR,OAAOA,GACL,OAAO;AAAA,UACP,MAAMA,GAAE,KAAK,CAAC,WAAW,CAAC,EAAE,QAAQ;AAAA,UACpC,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,UAC5B,eAAeA,GACb,OAAO;AAAA,YACP,MAAMA,GAAE,OAAO,EAAE,SAAS;AAAA,YAC1B,WAAWA,GAAE,OAAO,EAAE,SAAS;AAAA,UAChC,CAAC,EACA,QAAQ;AAAA,UACV,YAAYA,GACV;AAAA,YACAA,GAAE,OAAO;AAAA,cACR,OAAOA,GAAE,OAAO;AAAA,cAChB,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,cACvB,MAAMA,GAAE,QAAQ,UAAU,EAAE,SAAS;AAAA,cACrC,UAAUA,GAAE,OAAO;AAAA,gBAClB,MAAMA,GAAE,OAAO,EAAE,QAAQ;AAAA,gBACzB,WAAWA,GAAE,OAAO,EAAE,QAAQ;AAAA,cAC/B,CAAC;AAAA,YACF,CAAC;AAAA,UACF,EACC,QAAQ;AAAA,QACX,CAAC,EACA,QAAQ;AAAA,QACV,UAAUA,GACR,OAAO;AAAA,UACP,SAASA,GACP;AAAA,YACAA,GAAE,OAAO;AAAA,cACR,OAAOA,GAAE,OAAO;AAAA,cAChB,SAASA,GAAE,OAAO;AAAA,cAClB,cAAcA,GAAE;AAAA,gBACfA,GAAE,OAAO;AAAA,kBACR,OAAOA,GAAE,OAAO;AAAA,kBAChB,SAASA,GAAE,OAAO;AAAA,gBACnB,CAAC;AAAA,cACF;AAAA,YACD,CAAC;AAAA,UACF,EACC,SAAS;AAAA,QACZ,CAAC,EACA,QAAQ;AAAA,QACV,eAAeA,GAAE,OAAO,EAAE,SAAS,EAAE,SAAS;AAAA,QAC9C,OAAOA,GAAE,OAAO;AAAA,MACjB,CAAC;AAAA,IACF;AAAA,IACA,OAAO;AAAA,EACR,CAAC;AAAA,EACD;AACD,CAAC;AAED,SAAS,iBAAiB,SAAiB;AAC1C,SACC,YAAY,QACZ,QAAQ,WAAW,KAAK,KACxB,YAAY,QACZ,QAAQ,WAAW,KAAK;AAE1B;AAEA,SAAS,aAAa,SAAiB;AACtC,SAAO,QAAQ,WAAW,sBAAsB;AACjD;;;AO7zBA;AAAA,EAME,iCAAAC;AAAA,OACK;AACP;AAAA,EAGE,kBAAAC;AAAA,EACA,oCAAAC;AAAA,EACA,6BAAAC;AAAA,EACA,iBAAAC;AAAA,OACK;AACP,SAAS,KAAAC,UAAS;;;AChBlB;AAAA,EACE;AAAA,EAEA,iCAAAC;AAAA,OACK;AAEA,SAAS,gCAAgC;AAAA,EAC9C;AAAA,EACA;AAAA,EACA,OAAO;AAAA,EACP,YAAY;AACd,GAQE;AAEA,MACE,gBAAgB,YAChB,OAAO,WAAW,KAClB,OAAO,CAAC,EAAE,SAAS,UACnB,OAAO,CAAC,EAAE,QAAQ,WAAW,KAC7B,OAAO,CAAC,EAAE,QAAQ,CAAC,EAAE,SAAS,QAC9B;AACA,WAAO,EAAE,QAAQ,OAAO,CAAC,EAAE,QAAQ,CAAC,EAAE,KAAK;AAAA,EAC7C;AAGA,MAAI,OAAO;AAGX,MAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC/B,YAAQ,GAAG,OAAO,CAAC,EAAE,OAAO;AAAA;AAAA;AAC5B,aAAS,OAAO,MAAM,CAAC;AAAA,EACzB;AAEA,aAAW,EAAE,MAAM,QAAQ,KAAK,QAAQ;AACtC,YAAQ,MAAM;AAAA,MACZ,KAAK,UAAU;AACb,cAAM,IAAI,mBAAmB;AAAA,UAC3B,SAAS;AAAA,UACT;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MAEA,KAAK,QAAQ;AACX,cAAM,cAAc,QACjB,IAAI,UAAQ;AACX,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;AAAA,YACd;AAAA,YACA,KAAK,SAAS;AACZ,oBAAM,IAAIA,+BAA8B;AAAA,gBACtC,eAAe;AAAA,cACjB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF,CAAC,EACA,KAAK,EAAE;AAEV,gBAAQ,GAAG,IAAI;AAAA,EAAM,WAAW;AAAA;AAAA;AAChC;AAAA,MACF;AAAA,MAEA,KAAK,aAAa;AAChB,cAAM,mBAAmB,QACtB,IAAI,UAAQ;AACX,kBAAQ,KAAK,MAAM;AAAA,YACjB,KAAK,QAAQ;AACX,qBAAO,KAAK;AAAA,YACd;AAAA,YACA,KAAK,aAAa;AAChB,oBAAM,IAAIA,+BAA8B;AAAA,gBACtC,eAAe;AAAA,cACjB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF,CAAC,EACA,KAAK,EAAE;AAEV,gBAAQ,GAAG,SAAS;AAAA,EAAM,gBAAgB;AAAA;AAAA;AAC1C;AAAA,MACF;AAAA,MAEA,KAAK,QAAQ;AACX,cAAM,IAAIA,+BAA8B;AAAA,UACtC,eAAe;AAAA,QACjB,CAAC;AAAA,MACH;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAGA,UAAQ,GAAG,SAAS;AAAA;AAEpB,SAAO;AAAA,IACL,QAAQ;AAAA,IACR,eAAe,CAAC;AAAA,EAAK,IAAI,GAAG;AAAA,EAC9B;AACF;;;ACrGO,SAAS,4BACd,UACqC;AACrC,SAAO,qCAAU,OAAO,IAAI,CAAC,OAAO,WAAW;AAAA,IAC7C;AAAA,IACA,SAAS,SAAS,eAAe,KAAK;AAAA,IACtC,aAAa,SAAS,eAClB,OAAO,QAAQ,SAAS,aAAa,KAAK,CAAC,EAAE;AAAA,MAC3C,CAAC,CAACC,QAAO,OAAO,OAAO;AAAA,QACrB,OAAAA;AAAA,QACA;AAAA,MACF;AAAA,IACF,IACA,CAAC;AAAA,EACP;AACF;;;AFeO,IAAM,gCAAN,MAA+D;AAAA,EASpE,YACE,SACA,UACA,QACA;AAZF,SAAS,uBAAuB;AAChC,SAAS,8BAA8B;AAYrC,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,SAAS;AAAA,EAChB;AAAA,EAEA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEQ,QAAQ;AAAA,IACd;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,eAAe;AAAA,IACf;AAAA,IACA;AAAA,EACF,GAAiD;AA1EnD;AA2EI,UAAM,OAAO,KAAK;AAElB,UAAM,WAAyC,CAAC;AAEhD,QAAI,QAAQ,MAAM;AAChB,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,QAAI,kBAAkB,QAAQ,eAAe,SAAS,QAAQ;AAC5D,eAAS,KAAK;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SAAS;AAAA,MACX,CAAC;AAAA,IACH;AAEA,UAAM,EAAE,QAAQ,kBAAkB,cAAc,IAC9C,gCAAgC,EAAE,QAAQ,YAAY,CAAC;AAEzD,UAAM,OAAO,CAAC,GAAI,wCAAiB,CAAC,GAAI,GAAI,gDAAqB,CAAC,CAAE;AAEpE,UAAM,WAAW;AAAA;AAAA,MAEf,OAAO,KAAK;AAAA;AAAA,MAGZ,MAAM,KAAK,SAAS;AAAA,MACpB,YAAY,KAAK,SAAS;AAAA,MAC1B,UACE,OAAO,KAAK,SAAS,aAAa,WAC9B,KAAK,SAAS,WACd,OAAO,KAAK,SAAS,aAAa,YAClC,KAAK,SAAS,WACZ,IACA,SACF;AAAA,MACN,QAAQ,KAAK,SAAS;AAAA,MACtB,MAAM,KAAK,SAAS;AAAA;AAAA,MAGpB,YAAY;AAAA,MACZ;AAAA,MACA,OAAO;AAAA,MACP,mBAAmB;AAAA,MACnB,kBAAkB;AAAA,MAClB;AAAA;AAAA,MAGA,QAAQ;AAAA;AAAA,MAGR,MAAM,KAAK,SAAS,IAAI,OAAO;AAAA,IACjC;AAEA,YAAQ,MAAM;AAAA,MACZ,KAAK,WAAW;AACd,aAAI,UAAK,UAAL,mBAAY,QAAQ;AACtB,gBAAM,IAAIC,+BAA8B;AAAA,YACtC,eAAe;AAAA,UACjB,CAAC;AAAA,QACH;AAEA,YAAI,KAAK,YAAY;AACnB,gBAAM,IAAIA,+BAA8B;AAAA,YACtC,eAAe;AAAA,UACjB,CAAC;AAAA,QACH;AAEA,eAAO,EAAE,MAAM,UAAU,SAAS;AAAA,MACpC;AAAA,MAEA,KAAK,eAAe;AAClB,cAAM,IAAIA,+BAA8B;AAAA,UACtC,eAAe;AAAA,QACjB,CAAC;AAAA,MACH;AAAA,MAEA,KAAK,eAAe;AAClB,cAAM,IAAIA,+BAA8B;AAAA,UACtC,eAAe;AAAA,QACjB,CAAC;AAAA,MACH;AAAA,MAEA,SAAS;AACP,cAAM,mBAA0B;AAChC,cAAM,IAAI,MAAM,qBAAqB,gBAAgB,EAAE;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,WACJ,SAC6D;AAC7D,UAAM,EAAE,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAE/C,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMC,eAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,SAASC,gBAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D,MAAM;AAAA,MACN,uBAAuB;AAAA,MACvB,2BAA2BC;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,EAAE,QAAQ,WAAW,GAAG,YAAY,IAAI;AAC9C,UAAM,SAAS,SAAS,QAAQ,CAAC;AAEjC,WAAO;AAAA,MACL,MAAM,OAAO;AAAA,MACb,OAAO;AAAA,QACL,cAAc,SAAS,MAAM;AAAA,QAC7B,kBAAkB,SAAS,MAAM;AAAA,MACnC;AAAA,MACA,cAAc,sBAAsB,OAAO,aAAa;AAAA,MACxD,UAAU,4BAA4B,OAAO,QAAQ;AAAA,MACrD,SAAS,EAAE,WAAW,YAAY;AAAA,MAClC,aAAa,EAAE,SAAS,gBAAgB;AAAA,MACxC,UAAU,oBAAoB,QAAQ;AAAA,MACtC;AAAA,MACA,SAAS,EAAE,MAAM,KAAK,UAAU,IAAI,EAAE;AAAA,IACxC;AAAA,EACF;AAAA,EAEA,MAAM,SACJ,SAC2D;AAC3D,UAAM,EAAE,MAAM,SAAS,IAAI,KAAK,QAAQ,OAAO;AAE/C,UAAM,OAAO;AAAA,MACX,GAAG;AAAA,MACH,QAAQ;AAAA;AAAA,MAGR,gBACE,KAAK,OAAO,kBAAkB,WAC1B,EAAE,eAAe,KAAK,IACtB;AAAA,IACR;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMF,eAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,SAASC,gBAAe,KAAK,OAAO,QAAQ,GAAG,QAAQ,OAAO;AAAA,MAC9D;AAAA,MACA,uBAAuB;AAAA,MACvB,2BAA2BE;AAAA,QACzB;AAAA,MACF;AAAA,MACA,aAAa,QAAQ;AAAA,MACrB,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,UAAM,EAAE,QAAQ,WAAW,GAAG,YAAY,IAAI;AAE9C,QAAI,eAA4C;AAChD,QAAI,QAA4D;AAAA,MAC9D,cAAc,OAAO;AAAA,MACrB,kBAAkB,OAAO;AAAA,IAC3B;AACA,QAAI;AACJ,QAAI,eAAe;AAEnB,WAAO;AAAA,MACL,QAAQ,SAAS;AAAA,QACf,IAAI,gBAGF;AAAA,UACA,UAAU,OAAO,YAAY;AAE3B,gBAAI,CAAC,MAAM,SAAS;AAClB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,kBAAM,QAAQ,MAAM;AAGpB,gBAAI,WAAW,OAAO;AACpB,6BAAe;AACf,yBAAW,QAAQ,EAAE,MAAM,SAAS,OAAO,MAAM,MAAM,CAAC;AACxD;AAAA,YACF;AAEA,gBAAI,cAAc;AAChB,6BAAe;AAEf,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,GAAG,oBAAoB,KAAK;AAAA,cAC9B,CAAC;AAAA,YACH;AAEA,gBAAI,MAAM,SAAS,MAAM;AACvB,sBAAQ;AAAA,gBACN,cAAc,MAAM,MAAM;AAAA,gBAC1B,kBAAkB,MAAM,MAAM;AAAA,cAChC;AAAA,YACF;AAEA,kBAAM,SAAS,MAAM,QAAQ,CAAC;AAE9B,iBAAI,iCAAQ,kBAAiB,MAAM;AACjC,6BAAe,sBAAsB,OAAO,aAAa;AAAA,YAC3D;AAEA,iBAAI,iCAAQ,SAAQ,MAAM;AACxB,yBAAW,QAAQ;AAAA,gBACjB,MAAM;AAAA,gBACN,WAAW,OAAO;AAAA,cACpB,CAAC;AAAA,YACH;AAEA,kBAAM,iBAAiB;AAAA,cACrB,iCAAQ;AAAA,YACV;AACA,gBAAI,iDAAgB,QAAQ;AAC1B,kBAAI,aAAa,OAAW,YAAW,CAAC;AACxC,uBAAS,KAAK,GAAG,cAAc;AAAA,YACjC;AAAA,UACF;AAAA,UAEA,MAAM,YAAY;AAChB,uBAAW,QAAQ;AAAA,cACjB,MAAM;AAAA,cACN;AAAA,cACA;AAAA,cACA;AAAA,YACF,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAAA,MACH;AAAA,MACA,SAAS,EAAE,WAAW,YAAY;AAAA,MAClC,aAAa,EAAE,SAAS,gBAAgB;AAAA,MACxC;AAAA,MACA,SAAS,EAAE,MAAM,KAAK,UAAU,IAAI,EAAE;AAAA,IACxC;AAAA,EACF;AACF;AAIA,IAAM,iCAAiCC,GAAE,OAAO;AAAA,EAC9C,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,EACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,EAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;AAAA,EAC1B,SAASA,GAAE;AAAA,IACTA,GAAE,OAAO;AAAA,MACP,MAAMA,GAAE,OAAO;AAAA,MACf,eAAeA,GAAE,OAAO;AAAA,MACxB,UAAUA,GACP,OAAO;AAAA,QACN,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC;AAAA,QAC1B,gBAAgBA,GAAE,MAAMA,GAAE,OAAO,CAAC;AAAA,QAClC,cAAcA,GAAE,MAAMA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,SAAS;AAAA,MACnE,CAAC,EACA,QAAQ;AAAA,IACb,CAAC;AAAA,EACH;AAAA,EACA,OAAOA,GAAE,OAAO;AAAA,IACd,eAAeA,GAAE,OAAO;AAAA,IACxB,mBAAmBA,GAAE,OAAO;AAAA,EAC9B,CAAC;AACH,CAAC;AAID,IAAM,8BAA8BA,GAAE,MAAM;AAAA,EAC1CA,GAAE,OAAO;AAAA,IACP,IAAIA,GAAE,OAAO,EAAE,QAAQ;AAAA,IACvB,SAASA,GAAE,OAAO,EAAE,QAAQ;AAAA,IAC5B,OAAOA,GAAE,OAAO,EAAE,QAAQ;AAAA,IAC1B,SAASA,GAAE;AAAA,MACTA,GAAE,OAAO;AAAA,QACP,MAAMA,GAAE,OAAO;AAAA,QACf,eAAeA,GAAE,OAAO,EAAE,QAAQ;AAAA,QAClC,OAAOA,GAAE,OAAO;AAAA,QAChB,UAAUA,GACP,OAAO;AAAA,UACN,QAAQA,GAAE,MAAMA,GAAE,OAAO,CAAC;AAAA,UAC1B,gBAAgBA,GAAE,MAAMA,GAAE,OAAO,CAAC;AAAA,UAClC,cAAcA,GAAE,MAAMA,GAAE,OAAOA,GAAE,OAAO,GAAGA,GAAE,OAAO,CAAC,CAAC,EAAE,SAAS;AAAA,QACnE,CAAC,EACA,QAAQ;AAAA,MACb,CAAC;AAAA,IACH;AAAA,IACA,OAAOA,GACJ,OAAO;AAAA,MACN,eAAeA,GAAE,OAAO;AAAA,MACxB,mBAAmBA,GAAE,OAAO;AAAA,IAC9B,CAAC,EACA,QAAQ;AAAA,EACb,CAAC;AAAA,EACD;AACF,CAAC;;;AG7XD;AAAA,EAEE;AAAA,OACK;AACP;AAAA,EACE,kBAAAC;AAAA,EACA,6BAAAC;AAAA,EACA,iBAAAC;AAAA,OACK;AACP,SAAS,KAAAC,UAAS;AAQX,IAAM,uBAAN,MAA+D;AAAA,EAmBpE,YACE,SACA,UACA,QACA;AAtBF,SAAS,uBAAuB;AAuB9B,SAAK,UAAU;AACf,SAAK,WAAW;AAChB,SAAK,SAAS;AAAA,EAChB;AAAA,EApBA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAEA,IAAI,uBAA+B;AA5BrC;AA6BI,YAAO,UAAK,SAAS,yBAAd,YAAsC;AAAA,EAC/C;AAAA,EAEA,IAAI,wBAAiC;AAhCvC;AAiCI,YAAO,UAAK,SAAS,0BAAd,YAAuC;AAAA,EAChD;AAAA,EAYA,MAAM,QAAQ;AAAA,IACZ;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAEE;AACA,QAAI,OAAO,SAAS,KAAK,sBAAsB;AAC7C,YAAM,IAAI,mCAAmC;AAAA,QAC3C,UAAU,KAAK;AAAA,QACf,SAAS,KAAK;AAAA,QACd,sBAAsB,KAAK;AAAA,QAC3B;AAAA,MACF,CAAC;AAAA,IACH;AAEA,UAAM,EAAE,iBAAiB,OAAO,SAAS,IAAI,MAAMC,eAAc;AAAA,MAC/D,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,SAASC,gBAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;AAAA,MACtD,MAAM;AAAA,QACJ,OAAO,KAAK;AAAA,QACZ,OAAO;AAAA,QACP,iBAAiB;AAAA,QACjB,YAAY,KAAK,SAAS;AAAA,QAC1B,MAAM,KAAK,SAAS;AAAA,MACtB;AAAA,MACA,uBAAuB;AAAA,MACvB,2BAA2BC;AAAA,QACzB;AAAA,MACF;AAAA,MACA;AAAA,MACA,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,WAAO;AAAA,MACL,YAAY,SAAS,KAAK,IAAI,UAAQ,KAAK,SAAS;AAAA,MACpD,OAAO,SAAS,QACZ,EAAE,QAAQ,SAAS,MAAM,cAAc,IACvC;AAAA,MACJ,aAAa,EAAE,SAAS,gBAAgB;AAAA,IAC1C;AAAA,EACF;AACF;AAIA,IAAM,oCAAoCC,GAAE,OAAO;AAAA,EACjD,MAAMA,GAAE,MAAMA,GAAE,OAAO,EAAE,WAAWA,GAAE,MAAMA,GAAE,OAAO,CAAC,EAAE,CAAC,CAAC;AAAA,EAC1D,OAAOA,GAAE,OAAO,EAAE,eAAeA,GAAE,OAAO,EAAE,CAAC,EAAE,QAAQ;AACzD,CAAC;;;ACjGD;AAAA,EACE,kBAAAC;AAAA,EACA,6BAAAC;AAAA,EACA,iBAAAC;AAAA,OACK;AACP,SAAS,KAAAC,UAAS;AAMX,IAAM,mBAAN,MAA+C;AAAA,EAUpD,YAAY,SAA6B,QAAsB;AAT/D,SAAS,uBAAuB;AAU9B,SAAK,UAAU;AACf,SAAK,SAAS;AAAA,EAChB;AAAA,EAPA,IAAI,WAAmB;AACrB,WAAO,KAAK,OAAO;AAAA,EACrB;AAAA,EAOA,MAAM,WAAW;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAEE;AApCJ;AAqCI,UAAM,EAAE,OAAO,SAAS,IAAI,MAAMC,eAAc;AAAA,MAC9C,KAAK,KAAK,OAAO,IAAI;AAAA,QACnB,MAAM;AAAA,QACN,SAAS,KAAK;AAAA,MAChB,CAAC;AAAA,MACD,SAASC,gBAAe,KAAK,OAAO,QAAQ,GAAG,OAAO;AAAA,MACtD,MAAM;AAAA,QACJ,OAAO,KAAK;AAAA,QACZ;AAAA,QACA;AAAA,QACA;AAAA,QACA,IAAI,qBAAgB,WAAhB,YAA0B,CAAC;AAAA,QAC/B,iBAAiB;AAAA,MACnB;AAAA,MACA,uBAAuB;AAAA,MACvB,2BAA2BC;AAAA,QACzB;AAAA,MACF;AAAA,MACA;AAAA,MACA,OAAO,KAAK,OAAO;AAAA,IACrB,CAAC;AAED,WAAO;AAAA,MACL,QAAQ,SAAS,KAAK,IAAI,UAAQ,KAAK,QAAQ;AAAA,IACjD;AAAA,EACF;AACF;AAIA,IAAM,4BAA4BC,GAAE,OAAO;AAAA,EACzC,MAAMA,GAAE,MAAMA,GAAE,OAAO,EAAE,UAAUA,GAAE,OAAO,EAAE,CAAC,CAAC;AAClD,CAAC;;;AZuEM,SAAS,aACd,UAAkC,CAAC,GACnB;AA9IlB;AA+IE,QAAM,WACJ,0BAAqB,QAAQ,OAAO,MAApC,YAAyC;AAG3C,QAAM,iBAAgB,aAAQ,kBAAR,YAAyB;AAE/C,QAAM,gBAAe,aAAQ,SAAR,YAAgB;AAErC,QAAM,aAAa,OAAO;AAAA,IACxB,eAAe,UAAU,WAAW;AAAA,MAClC,QAAQ,QAAQ;AAAA,MAChB,yBAAyB;AAAA,MACzB,aAAa;AAAA,IACf,CAAC,CAAC;AAAA,IACF,uBAAuB,QAAQ;AAAA,IAC/B,kBAAkB,QAAQ;AAAA,IAC1B,GAAG,QAAQ;AAAA,EACb;AAEA,QAAM,kBAAkB,CACtB,SACA,WAA+B,CAAC,MAEhC,IAAI,wBAAwB,SAAS,UAAU;AAAA,IAC7C,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT;AAAA,IACA,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,wBAAwB,CAC5B,SACA,WAAqC,CAAC,MAEtC,IAAI,8BAA8B,SAAS,UAAU;AAAA,IACnD,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT;AAAA,IACA,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,uBAAuB,CAC3B,SACA,WAAoC,CAAC,MAErC,IAAI,qBAAqB,SAAS,UAAU;AAAA,IAC1C,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,mBAAmB,CAAC,YACxB,IAAI,iBAAiB,SAAS;AAAA,IAC5B,UAAU,GAAG,YAAY;AAAA,IACzB,KAAK,CAAC,EAAE,KAAK,MAAM,GAAG,OAAO,GAAG,IAAI;AAAA,IACpC,SAAS;AAAA,IACT,OAAO,QAAQ;AAAA,EACjB,CAAC;AAEH,QAAM,sBAAsB,CAC1B,SACA,aACG;AACH,QAAI,YAAY;AACd,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,QAAI,YAAY,0BAA0B;AACxC,aAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAEA,WAAO,gBAAgB,SAAS,QAA8B;AAAA,EAChE;AAEA,QAAM,WAAW,SACf,SACA,UACA;AACA,WAAO,oBAAoB,SAAS,QAAQ;AAAA,EAC9C;AAEA,WAAS,gBAAgB;AACzB,WAAS,OAAO;AAChB,WAAS,aAAa;AACtB,WAAS,YAAY;AACrB,WAAS,gBAAgB;AACzB,WAAS,qBAAqB;AAC9B,WAAS,QAAQ;AAEjB,SAAO;AACT;AAKO,IAAM,SAAS,aAAa;AAAA,EACjC,eAAe;AAAA;AACjB,CAAC;","names":["UnsupportedFunctionalityError","z","token","logprob","UnsupportedFunctionalityError","type","UnsupportedFunctionalityError","_a","toolCall","z","UnsupportedFunctionalityError","combineHeaders","createEventSourceResponseHandler","createJsonResponseHandler","postJsonToApi","z","UnsupportedFunctionalityError","token","UnsupportedFunctionalityError","postJsonToApi","combineHeaders","createJsonResponseHandler","createEventSourceResponseHandler","z","combineHeaders","createJsonResponseHandler","postJsonToApi","z","postJsonToApi","combineHeaders","createJsonResponseHandler","z","combineHeaders","createJsonResponseHandler","postJsonToApi","z","postJsonToApi","combineHeaders","createJsonResponseHandler","z"]}